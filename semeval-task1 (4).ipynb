{"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"3d74325d07604d35962fe2276fb953e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c04a64503144fbbadbf38c4a8a400af","IPY_MODEL_a654022f869b483ba314514f3d33eebc","IPY_MODEL_1a290b121d5b4c47879a6cbeb7c74e4b"],"layout":"IPY_MODEL_02672ac421834496ab3c7b33e1af6715"}},"3c04a64503144fbbadbf38c4a8a400af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf31941cbca4c2cb0c2a94ca40230fd","placeholder":"​","style":"IPY_MODEL_75974fe9fb2f440aa094cac1ef43afa5","value":"Downloading: 100%"}},"a654022f869b483ba314514f3d33eebc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3377e84b2dfd4fb8b06004f1a2d13000","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9ba39b092694099b89b5f18db586c65","value":231508}},"1a290b121d5b4c47879a6cbeb7c74e4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c49a53fb18db4f4ca27b357bde5b9fcc","placeholder":"​","style":"IPY_MODEL_858a38ccecae4495b817bf5e3c72ac78","value":" 232k/232k [00:00&lt;00:00, 1.91MB/s]"}},"02672ac421834496ab3c7b33e1af6715":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf31941cbca4c2cb0c2a94ca40230fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75974fe9fb2f440aa094cac1ef43afa5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3377e84b2dfd4fb8b06004f1a2d13000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ba39b092694099b89b5f18db586c65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c49a53fb18db4f4ca27b357bde5b9fcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"858a38ccecae4495b817bf5e3c72ac78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d7247e3baa488da51b2e469f81410e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cc724dd6fd74e4d8c64447b45dbf8b0","IPY_MODEL_0e792299a2434c30a6204854937f9fab","IPY_MODEL_4c3c1766816a498ab53c2a07763e0d0e"],"layout":"IPY_MODEL_034b91dc113f4caeb99a9de25cd1f164"}},"3cc724dd6fd74e4d8c64447b45dbf8b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a51d8a0521bd4dbab512633ab540251b","placeholder":"​","style":"IPY_MODEL_bedfc88f1ed74dd2aebb9055f7f53962","value":"Downloading: 100%"}},"0e792299a2434c30a6204854937f9fab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ce55eb40a534ab488c6617d83c9f232","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5d3e641bada4a1e8a9f806c290a113e","value":28}},"4c3c1766816a498ab53c2a07763e0d0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_634e29b6e7914052a5798344dd70a123","placeholder":"​","style":"IPY_MODEL_f144322c1bea4cda861acd90979b9501","value":" 28.0/28.0 [00:00&lt;00:00, 493B/s]"}},"034b91dc113f4caeb99a9de25cd1f164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a51d8a0521bd4dbab512633ab540251b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bedfc88f1ed74dd2aebb9055f7f53962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ce55eb40a534ab488c6617d83c9f232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5d3e641bada4a1e8a9f806c290a113e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"634e29b6e7914052a5798344dd70a123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f144322c1bea4cda861acd90979b9501":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9c89384f59f4205a926a7d5047a65d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2206e61e87f146a6a9e41e2a1b9ce6e5","IPY_MODEL_fc20535ac9bb40eeaf6cf0ac03204f5d","IPY_MODEL_bb5a68eb90b5483f850ef1fa571161bf"],"layout":"IPY_MODEL_746810f979df4679b1bb6b62c92f4c6b"}},"2206e61e87f146a6a9e41e2a1b9ce6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6148c4b64bec454886369261622ec194","placeholder":"​","style":"IPY_MODEL_261eda0157764307bd542abbe3a1a5ba","value":"Downloading: 100%"}},"fc20535ac9bb40eeaf6cf0ac03204f5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d330293ab71c447680b9464824521bc2","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f804a1e2c0841dab831ca6f8e077930","value":570}},"bb5a68eb90b5483f850ef1fa571161bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4762359b3eda444183720fb2c5dc20b2","placeholder":"​","style":"IPY_MODEL_b394aa448a5241c8af4e4ba5aa45fb95","value":" 570/570 [00:00&lt;00:00, 14.7kB/s]"}},"746810f979df4679b1bb6b62c92f4c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6148c4b64bec454886369261622ec194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"261eda0157764307bd542abbe3a1a5ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d330293ab71c447680b9464824521bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f804a1e2c0841dab831ca6f8e077930":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4762359b3eda444183720fb2c5dc20b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b394aa448a5241c8af4e4ba5aa45fb95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fd423bcb37549fbac67196c0a04cc36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d196ea0fff8349b49f056e71170a0b9f","IPY_MODEL_f48320c1d51e48e280982ef318ddd77f","IPY_MODEL_2c22234b9966431690f6c6336cf54095"],"layout":"IPY_MODEL_ea577aebbad24266aa3fb214eddc3fb1"}},"d196ea0fff8349b49f056e71170a0b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a304bb2d2d846f1b20dab41b1a5022e","placeholder":"​","style":"IPY_MODEL_1060e4f1e31c442dae93ad4677d78751","value":"Downloading: 100%"}},"f48320c1d51e48e280982ef318ddd77f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dceb0f63f9da45b782ca641627846ad8","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b109be86a87a417397d969a335b76e3a","value":440473133}},"2c22234b9966431690f6c6336cf54095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0476225cfd49f480a19a4c239ff057","placeholder":"​","style":"IPY_MODEL_850e990ccfaf47b4b5afb62e3bc242e0","value":" 440M/440M [00:22&lt;00:00, 23.9MB/s]"}},"ea577aebbad24266aa3fb214eddc3fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a304bb2d2d846f1b20dab41b1a5022e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1060e4f1e31c442dae93ad4677d78751":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dceb0f63f9da45b782ca641627846ad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b109be86a87a417397d969a335b76e3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb0476225cfd49f480a19a4c239ff057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"850e990ccfaf47b4b5afb62e3bc242e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Importing the libraries\n\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nimport sys\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report as report\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport argparse\nimport torch\nimport numpy as np\nimport torch.nn as nn\ntorch.cuda.empty_cache()\n","metadata":{"id":"vpPWPELNwifu","execution":{"iopub.status.busy":"2022-11-12T12:23:59.950617Z","iopub.execute_input":"2022-11-12T12:23:59.951333Z","iopub.status.idle":"2022-11-12T12:24:00.015667Z","shell.execute_reply.started":"2022-11-12T12:23:59.951295Z","shell.execute_reply":"2022-11-12T12:24:00.014555Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"def make_dataframe(input_folder, labels_folder=None):\n    #MAKE TXT DATAFRAME\n    text = []\n    \n    for fil in tqdm(filter(lambda x: x.endswith('.txt'), os.listdir(input_folder))):\n\n        iD, txt = fil[7:].split('.')[0], open(input_folder +fil, 'r', encoding='utf-8').read() \n        text.append((iD, txt))\n\n    df_text = pd.DataFrame(text, columns=['id','text']).set_index('id')\n\n    df = df_text\n\n    #MAKE LABEL DATAFRAME\n    if labels_folder:\n        labels = pd.read_csv(labels_folder, sep='\\t', header=None)\n        labels = labels.rename(columns={0:'id',1:'type'})\n        labels.id = labels.id.apply(str)\n        labels = labels.set_index('id')\n\n        #JOIN\n        df = labels.join(df_text)[['text','type']]\n\n    return df\n\n   \n\n","metadata":{"id":"VQ3XE385wvV7","execution":{"iopub.status.busy":"2022-11-12T12:24:00.017748Z","iopub.execute_input":"2022-11-12T12:24:00.018649Z","iopub.status.idle":"2022-11-12T12:24:00.030371Z","shell.execute_reply.started":"2022-11-12T12:24:00.018593Z","shell.execute_reply":"2022-11-12T12:24:00.029360Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"id":"8MAs60RdVlDK"}},{"cell_type":"code","source":"## Making the dataframe\n\nfolder_train =\"../input/semeval-data/train-articles-subtask-1/\"\nlabels_train_fn =\"../input/semeval-data/train-labels-subtask-1.txt\"\nfolder_dev = \"../input/semeval-data/dev-articles-subtask-1/\"\n\n #Read Data\nprint('Loading training...')\ntrain = make_dataframe(folder_train, labels_train_fn)\n \nprint('Loading dev...')\ntest = make_dataframe(folder_dev)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9KZiPqD4DA4","outputId":"1bb98d85-a04a-4b2f-9d98-e0c4f2ff584e","execution":{"iopub.status.busy":"2022-11-12T12:24:00.033479Z","iopub.execute_input":"2022-11-12T12:24:00.034096Z","iopub.status.idle":"2022-11-12T12:24:00.393120Z","shell.execute_reply.started":"2022-11-12T12:24:00.034061Z","shell.execute_reply":"2022-11-12T12:24:00.392051Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Loading training...\n","output_type":"stream"},{"name":"stderr","text":"433it [00:00, 1542.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loading dev...\n","output_type":"stream"},{"name":"stderr","text":"83it [00:00, 2098.87it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"## Example training text\n\nprint((train[\"text\"][0]))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUgLYep_c150","outputId":"9d67e4dc-94ba-4223-c8e1-3a3effd899e7","execution":{"iopub.status.busy":"2022-11-12T12:24:00.395717Z","iopub.execute_input":"2022-11-12T12:24:00.396106Z","iopub.status.idle":"2022-11-12T12:24:00.402191Z","shell.execute_reply.started":"2022-11-12T12:24:00.396067Z","shell.execute_reply":"2022-11-12T12:24:00.401064Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Chelsea Handler Admits She’s ‘Very Sexually Attracted to Robert Mueller’\n\nFar-left comedienne Chelsea Handler has admitted she is “very sexually attracted” to FBI Special Counsel Robert Mueller, just hours after he concluded his investigations into supposed collusion between Russia and Donald Trump’s presidential campaign.\nOn Friday evening, the Justice Department announced that Mueller had concluded his investigations into the matter and that he would not be recommending any more indictments against Trump or anyone else involved in his campaign.\nYet despite the weight of disappointment felt by the majority on the Hollywood left, Chelsea Handler admitted that her obsession with the 74-year-old prosecutor may have been because she found him sexually attractive.\n“If I’m being completely honest, I am very sexually attracted to Robert Mueller,” she wrote on Twitter.\n“I know it’s not meant to be, but that doesn’t mean I won’t hang a poster of him above my bed.”\nIf I’m being completely honest, I am very sexually attracted to Robert Mueller.\nI know it’s not meant to be, but that doesn’t mean I won’t hang a poster of him above my bed.\n— Chelsea Handler (@chelseahandler) March 23, 2019\nLast month, the failed Netflix talk show host wished Mueller a “Happy Valentines Day,” while expressing hope that he would soon indict the president’s son Donald Trump Jr. on charges of Russian collusion or some financial misdemeanor.\n“Happy Valentines Day to Robert Mueller, and for him giving his final rose to DonaldTrump, Jr.,” she wrote.\n“That would make this holiday really count.”\nMueller’s final report has not yet been released, although Attorney General William Barr said on Friday that he could reveal its contents as soon as this weekend.\n“I am reviewing the report and anticipate that I may be in a position to advise you of the special counsel’s principal conclusions as soon as this weekend,” Barr wrote in his letter the top Republicans and Democrats on the House and Senate Judiciary committees.\nFollow Ben Kew on Facebook, Twitter at @ben_kew, or email him at bkew@breitbart.com.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example length of article \n\nprint(len(train[\"text\"]))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqT-M-RIhAdf","outputId":"c3d0a46a-e729-41f4-d534-4731ed01b0cf","execution":{"iopub.status.busy":"2022-11-12T12:24:00.404190Z","iopub.execute_input":"2022-11-12T12:24:00.404626Z","iopub.status.idle":"2022-11-12T12:24:00.413415Z","shell.execute_reply.started":"2022-11-12T12:24:00.404520Z","shell.execute_reply":"2022-11-12T12:24:00.412251Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"433\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import nltk library\n\nimport nltk\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:24:00.415539Z","iopub.execute_input":"2022-11-12T12:24:00.416428Z","iopub.status.idle":"2022-11-12T12:24:00.424761Z","shell.execute_reply.started":"2022-11-12T12:24:00.416391Z","shell.execute_reply":"2022-11-12T12:24:00.423572Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"## Here are some puctuations to remove from the dataset\n\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\n\n## Clean the text \n\ndef clean_text(x):\n    x = str(x)\n\n    for punct in puncts:\n       if punct in x:\n          x = x.replace(punct, f' {punct} ')\n\n        \n    return x\n\nimport re\n\n# Remove the numbers from the dataset\n\ndef clean_numbers(x):\n    if bool(re.search(r'\\d', x)):\n        x = re.sub('[0-9]{5,}', '#####', x)\n        x = re.sub('[0-9]{4}', '####', x)\n        x = re.sub('[0-9]{3}', '###', x)\n        x = re.sub('[0-9]{2}', '##', x)\n    return x    \n\nmispell_dict = {\"doesn’t\":\"does not\",\"i’m\":\"i am\",\"she’s\":\"she is\",\"it’s\":\"it is\",\"ain’t\": \"is not\", \"aren’t\": \"are not\",\"can’t\": \"cannot\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\", \"didn’t\": \"did not\",  \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he would\",\"he’ll\": \"he will\", \"he’s\": \"he is\", \"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\",  \"I’d\": \"I would\", \"I’d've\": \"I would have\", \"I’ll\": \"I will\", \"I’ll've\": \"I will have\",\"I’m\": \"I am\", \"I’ve\": \"I have\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\", \"i’ll\": \"i will\",  \"i’ll’ve\": \"i will have\",\"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\", \"it’d’ve\": \"it would have\", \"it’ll\": \"it will\", \"it’ll've\": \"it will have\",\"it’s\": \"it is\", \"let’s\": \"let us\", \"ma’am\": \"madam\", \"mayn’t\": \"may not\", \"might’ve\": \"might have\",\"mightn’t\": \"might not\",\"mightn’’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\", \"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\",\"o’clock\": \"of the clock\", \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\", \"shan’t\": \"shall not\", \"sha’n’t\": \"shall not\", \"shan’t’ve\": \"shall not have\", \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\", \"she’ll’ve\": \"she will have\", \"she’s\": \"she is\", \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\", \"so’ve\": \"so have\",\"so’s\": \"so as\", \"this’s\": \"this is\",\"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\", \"there’d’ve\": \"there would have\", \"there’s\": \"there is\", \"here’s\": \"here is\",\"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\", \"they’ll've\": \"they will have\", \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\", \"we’d’ve\": \"we would have\", \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\", \"what’ll’ve\": \"what will have\", \"what’re\": \"what are\",  \"what’s\": \"what is\", \"what’ve\": \"what have\", \"when’s\": \"when is\", \"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\", \"who’ll’ve\": \"who will have\", \"who’s\": \"who is\", \"who’ve\": \"who have\", \"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\", \"won’t\": \"will not\", \"won’t've\": \"will not have\", \"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\",\"y’all’d’ve\": \"you all would have\",\"y’all’re\": \"you all are\",\"y’all’ve\": \"you all have\",\"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\", \"you’re\": \"you are\", \"you’ve\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\n\n## Replace the typical misspelled words and shorthands(like can't= cannot)\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n    return mispellings_re.sub(replace, text)\n\n\n# For removing punctuations\nimport string\nstring.punctuation\n\nfrom nltk.stem import WordNetLemmatizer\n\n\n## We lemmaatize the input text to transform similar words into one\n\n\n#defining the function to remove punctuation\ndef remove_punc(text):\n    wordnet_lemmatizer = WordNetLemmatizer() #defining the object for Lemmatization\n    punctuationfree =\"\".join([i for i in text if i not in string.punctuation])\n    punctuationfree = punctuationfree.replace('“', '')\n    punctuationfree = punctuationfree.replace(\"‘\", \"\")\n    punctuationfree = punctuationfree.replace(\"’\",\"\")\n    punctuationfree = punctuationfree.replace(\"”\",\"\")\n    punctuationfree = punctuationfree.replace(\"—\",\"\")\n    punctuationfree = punctuationfree.replace(\"\\n\",\" \")\n    return punctuationfree\n    ","metadata":{"id":"mXY6XaMsW-uQ","execution":{"iopub.status.busy":"2022-11-12T12:24:00.426989Z","iopub.execute_input":"2022-11-12T12:24:00.427753Z","iopub.status.idle":"2022-11-12T12:24:00.454706Z","shell.execute_reply.started":"2022-11-12T12:24:00.427717Z","shell.execute_reply":"2022-11-12T12:24:00.453726Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"print(mispellings_re)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1oWgU0PioIH","outputId":"c431d087-0412-4bef-f5f3-24376904cb3b","execution":{"iopub.status.busy":"2022-11-12T12:24:00.455865Z","iopub.execute_input":"2022-11-12T12:24:00.456438Z","iopub.status.idle":"2022-11-12T12:24:00.468357Z","shell.execute_reply.started":"2022-11-12T12:24:00.456402Z","shell.execute_reply":"2022-11-12T12:24:00.467303Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"re.compile(\"(doesn’t|i’m|she’s|it’s|ain’t|aren’t|can’t|’cause|could’ve|couldn’t|didn’t|don’t|hadn’t|hasn’t|haven’t|he’d|he’ll|he’s|how’d|how’d’y|how’ll|how’s|I’d|I’d've|I’ll|I’ll've|I’m|I’ve|i’d|i’d’ve|i’ll|i’ll)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Preprocessing the training and test data \n\n\n## Convert all to lowercase\ntrain[\"text\"] = train[\"text\"].apply(lambda x: x.lower())\ntest[\"text\"] = test[\"text\"].apply(lambda x: x.lower())\n\n## Clean the numbers\ntrain[\"text\"] = train[\"text\"].apply(lambda x: clean_numbers(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: clean_numbers(x))\n    \n# Clean spellings and remove short forms\ntrain[\"text\"] = train[\"text\"].apply(lambda x: replace_typical_misspell(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: replace_typical_misspell(x))\n\n","metadata":{"id":"21zJG30vaQDI","execution":{"iopub.status.busy":"2022-11-12T12:24:00.473125Z","iopub.execute_input":"2022-11-12T12:24:00.473824Z","iopub.status.idle":"2022-11-12T12:24:02.222531Z","shell.execute_reply.started":"2022-11-12T12:24:00.473788Z","shell.execute_reply":"2022-11-12T12:24:02.221511Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"#train[\"text\"] = train[\"text\"].apply(lambda x: clean_text(x))\n#test[\"text\"] = test[\"text\"].apply(lambda x: clean_text(x))\n\n## Remove punctuations\ntrain[\"text\"] = train[\"text\"].apply(lambda x: remove_punc(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: remove_punc(x))\n\n\n## fill up the missing values\nX_train = train[\"text\"].fillna(\"_##_\").values\nX_test = test[\"text\"].fillna(\"_##_\").values\n","metadata":{"id":"yo1h1Btmv7sT","execution":{"iopub.status.busy":"2022-11-12T12:24:02.224037Z","iopub.execute_input":"2022-11-12T12:24:02.227628Z","iopub.status.idle":"2022-11-12T12:24:02.548238Z","shell.execute_reply.started":"2022-11-12T12:24:02.227575Z","shell.execute_reply":"2022-11-12T12:24:02.547172Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"## Example text after preprocessing\n\nprint(train[\"text\"][0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHdrzufYxX3T","outputId":"c4515e5d-014d-42dd-c828-19b0f6c7eb22","execution":{"iopub.status.busy":"2022-11-12T12:24:02.549993Z","iopub.execute_input":"2022-11-12T12:24:02.550347Z","iopub.status.idle":"2022-11-12T12:24:02.557109Z","shell.execute_reply.started":"2022-11-12T12:24:02.550308Z","shell.execute_reply":"2022-11-12T12:24:02.555845Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"chelsea handler admits she is very sexually attracted to robert mueller  farleft comedienne chelsea handler has admitted she is very sexually attracted to fbi special counsel robert mueller just hours after he concluded his investigations into supposed collusion between russia and donald trumps presidential campaign on friday evening the justice department announced that mueller had concluded his investigations into the matter and that he would not be recommending any more indictments against trump or anyone else involved in his campaign yet despite the weight of disappointment felt by the majority on the hollywood left chelsea handler admitted that her obsession with the yearold prosecutor may have been because she found him sexually attractive if i am being completely honest i am very sexually attracted to robert mueller she wrote on twitter i know it is not meant to be but that does not mean i will not hang a poster of him above my bed if i am being completely honest i am very sexually attracted to robert mueller i know it is not meant to be but that does not mean i will not hang a poster of him above my bed  chelsea handler chelseahandler march   last month the failed netflix talk show host wished mueller a happy valentines day while expressing hope that he would soon indict the presidents son donald trump jr on charges of russian collusion or some financial misdemeanor happy valentines day to robert mueller and for him giving his final rose to donaldtrump jr she wrote that would make this holiday really count muellers final report has not yet been released although attorney general william barr said on friday that he could reveal its contents as soon as this weekend i am reviewing the report and anticipate that i may be in a position to advise you of the special counsels principal conclusions as soon as this weekend barr wrote in his letter the top republicans and democrats on the house and senate judiciary committees follow ben kew on facebook twitter at benkew or email him at bkewbreitbartcom  \n","output_type":"stream"}]},{"cell_type":"code","source":"## Pip install the transformers library\n\n!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eppDSmFL-wS6","outputId":"cf409681-d8f5-450b-889f-62c060fb8e9b","execution":{"iopub.status.busy":"2022-11-12T12:24:02.558998Z","iopub.execute_input":"2022-11-12T12:24:02.560247Z","iopub.status.idle":"2022-11-12T12:24:11.930973Z","shell.execute_reply.started":"2022-11-12T12:24:02.560211Z","shell.execute_reply":"2022-11-12T12:24:11.929365Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"## Defining the Bert model to be used for training\n\nfrom transformers import BertTokenizer, BertModel\n\n# Load pre-trained model tokenizer (vocabulary)\n#tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n\n#from transformers import AutoTokenizer\n#tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n\n\n## Initialize the tokenizer from the bert-base-uncased model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["3d74325d07604d35962fe2276fb953e2","3c04a64503144fbbadbf38c4a8a400af","a654022f869b483ba314514f3d33eebc","1a290b121d5b4c47879a6cbeb7c74e4b","02672ac421834496ab3c7b33e1af6715","baf31941cbca4c2cb0c2a94ca40230fd","75974fe9fb2f440aa094cac1ef43afa5","3377e84b2dfd4fb8b06004f1a2d13000","e9ba39b092694099b89b5f18db586c65","c49a53fb18db4f4ca27b357bde5b9fcc","858a38ccecae4495b817bf5e3c72ac78","e6d7247e3baa488da51b2e469f81410e","3cc724dd6fd74e4d8c64447b45dbf8b0","0e792299a2434c30a6204854937f9fab","4c3c1766816a498ab53c2a07763e0d0e","034b91dc113f4caeb99a9de25cd1f164","a51d8a0521bd4dbab512633ab540251b","bedfc88f1ed74dd2aebb9055f7f53962","0ce55eb40a534ab488c6617d83c9f232","b5d3e641bada4a1e8a9f806c290a113e","634e29b6e7914052a5798344dd70a123","f144322c1bea4cda861acd90979b9501","e9c89384f59f4205a926a7d5047a65d7","2206e61e87f146a6a9e41e2a1b9ce6e5","fc20535ac9bb40eeaf6cf0ac03204f5d","bb5a68eb90b5483f850ef1fa571161bf","746810f979df4679b1bb6b62c92f4c6b","6148c4b64bec454886369261622ec194","261eda0157764307bd542abbe3a1a5ba","d330293ab71c447680b9464824521bc2","0f804a1e2c0841dab831ca6f8e077930","4762359b3eda444183720fb2c5dc20b2","b394aa448a5241c8af4e4ba5aa45fb95"]},"id":"D1TOXZQh6EQA","outputId":"1888efb2-f313-4ab1-f7a1-30a00e92ad47","execution":{"iopub.status.busy":"2022-11-12T12:24:11.933151Z","iopub.execute_input":"2022-11-12T12:24:11.933553Z","iopub.status.idle":"2022-11-12T12:24:14.291837Z","shell.execute_reply.started":"2022-11-12T12:24:11.933514Z","shell.execute_reply":"2022-11-12T12:24:14.290800Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"X_train=X_train.tolist()\n","metadata":{"id":"ffNX8_WgFcf6","execution":{"iopub.status.busy":"2022-11-12T12:24:14.293271Z","iopub.execute_input":"2022-11-12T12:24:14.293684Z","iopub.status.idle":"2022-11-12T12:24:14.300896Z","shell.execute_reply.started":"2022-11-12T12:24:14.293648Z","shell.execute_reply":"2022-11-12T12:24:14.298427Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"type(X_train)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbIzgF8fHIo9","outputId":"855308d2-ea29-4f83-8473-edac6ede7e7b","execution":{"iopub.status.busy":"2022-11-12T12:24:14.302707Z","iopub.execute_input":"2022-11-12T12:24:14.303116Z","iopub.status.idle":"2022-11-12T12:24:14.313135Z","shell.execute_reply.started":"2022-11-12T12:24:14.303057Z","shell.execute_reply":"2022-11-12T12:24:14.312241Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"\nX_train[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"nCKgNMc7H-JR","outputId":"4593a337-192e-4e76-eac7-930b42b18925","execution":{"iopub.status.busy":"2022-11-12T12:24:14.314842Z","iopub.execute_input":"2022-11-12T12:24:14.315358Z","iopub.status.idle":"2022-11-12T12:24:14.323346Z","shell.execute_reply.started":"2022-11-12T12:24:14.315323Z","shell.execute_reply":"2022-11-12T12:24:14.322173Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"'chelsea handler admits she is very sexually attracted to robert mueller  farleft comedienne chelsea handler has admitted she is very sexually attracted to fbi special counsel robert mueller just hours after he concluded his investigations into supposed collusion between russia and donald trumps presidential campaign on friday evening the justice department announced that mueller had concluded his investigations into the matter and that he would not be recommending any more indictments against trump or anyone else involved in his campaign yet despite the weight of disappointment felt by the majority on the hollywood left chelsea handler admitted that her obsession with the yearold prosecutor may have been because she found him sexually attractive if i am being completely honest i am very sexually attracted to robert mueller she wrote on twitter i know it is not meant to be but that does not mean i will not hang a poster of him above my bed if i am being completely honest i am very sexually attracted to robert mueller i know it is not meant to be but that does not mean i will not hang a poster of him above my bed  chelsea handler chelseahandler march   last month the failed netflix talk show host wished mueller a happy valentines day while expressing hope that he would soon indict the presidents son donald trump jr on charges of russian collusion or some financial misdemeanor happy valentines day to robert mueller and for him giving his final rose to donaldtrump jr she wrote that would make this holiday really count muellers final report has not yet been released although attorney general william barr said on friday that he could reveal its contents as soon as this weekend i am reviewing the report and anticipate that i may be in a position to advise you of the special counsels principal conclusions as soon as this weekend barr wrote in his letter the top republicans and democrats on the house and senate judiciary committees follow ben kew on facebook twitter at benkew or email him at bkewbreitbartcom  '"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer \n\n# Init the Wordnet Lemmatizer\nlemmatizer = WordNetLemmatizer()\n\n## Lemmatize the text\n\nX_train_new=[]\n\nfor sent in X_train:\n  word_list = nltk.word_tokenize(sent)\n  lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n  X_train_new.append(lemmatized_output)\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:24:14.325704Z","iopub.execute_input":"2022-11-12T12:24:14.326311Z","iopub.status.idle":"2022-11-12T12:24:17.074124Z","shell.execute_reply.started":"2022-11-12T12:24:14.326273Z","shell.execute_reply":"2022-11-12T12:24:17.073100Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"X_train_new[0]\nX_train=X_train_new\n","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:24:17.075858Z","iopub.execute_input":"2022-11-12T12:24:17.076246Z","iopub.status.idle":"2022-11-12T12:24:17.081703Z","shell.execute_reply.started":"2022-11-12T12:24:17.076208Z","shell.execute_reply":"2022-11-12T12:24:17.080644Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize the inputs by adding CLS, SEP, PAD\n\n\n\n","metadata":{"id":"iNyW6YDCQBnH"}},{"cell_type":"code","source":"## Tokenize the sentences \n\n##(This adds padding to each of the sentences , adds a <CLS> token to the beginning of the text)\n\nX_train_tokenized=tokenizer(X_train,padding=True,truncation=True,return_tensors=\"pt\")\n","metadata":{"id":"X8IpND3jJpIq","execution":{"iopub.status.busy":"2022-11-12T12:24:17.083113Z","iopub.execute_input":"2022-11-12T12:24:17.084153Z","iopub.status.idle":"2022-11-12T12:24:28.315475Z","shell.execute_reply.started":"2022-11-12T12:24:17.084108Z","shell.execute_reply":"2022-11-12T12:24:28.314496Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"## Example of the token indices for an article\n\nprint((X_train_tokenized[\"input_ids\"])[0])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAYUH1HGJ1O1","outputId":"95f5de59-11e8-469a-8239-6c2fc5dcd19e","execution":{"iopub.status.busy":"2022-11-12T12:24:28.317100Z","iopub.execute_input":"2022-11-12T12:24:28.317720Z","iopub.status.idle":"2022-11-12T12:24:28.327422Z","shell.execute_reply.started":"2022-11-12T12:24:28.317683Z","shell.execute_reply":"2022-11-12T12:24:28.326312Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"tensor([  101,  9295, 28213, 14456,  2016,  2003,  2200, 12581,  6296,  2000,\n         2728, 26774,  2521,  2571,  6199,  2272, 10265, 10087,  9295, 28213,\n         5292,  4914,  2016,  2003,  2200, 12581,  6296,  2000,  8495,  2569,\n         9517,  2728, 26774,  2074,  3178,  2044,  2002,  5531,  2010,  4812,\n         2046,  4011,  8902, 24117,  2090,  3607,  1998,  6221,  8398,  4883,\n         3049,  2006,  5958,  3944,  1996,  3425,  2533,  2623,  2008, 26774,\n         2018,  5531,  2010,  4812,  2046,  1996,  3043,  1998,  2008,  2002,\n         2052,  2025,  2022, 16755,  2075,  2151,  2062, 24265,  2114,  8398,\n         2030,  3087,  2842,  2920,  1999,  2010,  3049,  2664,  2750,  1996,\n         3635,  1997, 10520,  2371,  2011,  1996,  3484,  2006,  1996,  5365,\n         2187,  9295, 28213,  4914,  2008,  2014, 17418,  2007,  1996,  2095,\n        11614, 12478,  2089,  2031,  2042,  2138,  2016,  2179,  2032, 12581,\n         8702,  2065,  1045,  2572,  2108,  3294,  7481,  1045,  2572,  2200,\n        12581,  6296,  2000,  2728, 26774,  2016,  2626,  2006, 10474,  1045,\n         2113,  2009,  2003,  2025,  3214,  2000,  2022,  2021,  2008, 18629,\n         2025,  2812,  1045,  2097,  2025,  6865,  1037, 13082,  1997,  2032,\n         2682,  2026,  2793,  2065,  1045,  2572,  2108,  3294,  7481,  1045,\n         2572,  2200, 12581,  6296,  2000,  2728, 26774,  1045,  2113,  2009,\n         2003,  2025,  3214,  2000,  2022,  2021,  2008, 18629,  2025,  2812,\n         1045,  2097,  2025,  6865,  1037, 13082,  1997,  2032,  2682,  2026,\n         2793,  9295, 28213,  9295, 11774,  3917,  2233,  2197,  3204,  1996,\n         3478, 20907,  2831,  2265,  3677,  6257, 26774,  1037,  3407, 10113,\n         2154,  2096, 14026,  3246,  2008,  2002,  2052,  2574, 27427,  2594,\n         2102,  1996,  2343,  2365,  6221,  8398,  3781,  2006,  3715,  1997,\n         2845,  8902, 24117,  2030,  2070,  3361, 28616,  3207,  4168, 27869,\n         3407, 10113,  2154,  2000,  2728, 26774,  1998,  2005,  2032,  3228,\n         2010,  2345,  3123,  2000,  6221, 24456,  2361,  3781,  2016,  2626,\n         2008,  2052,  2191,  2023,  6209,  2428,  4175, 26774,  2015,  2345,\n         3189,  5292,  2025,  2664,  2042,  2207,  2348,  4905,  2236,  2520,\n        19820,  2056,  2006,  5958,  2008,  2002,  2071,  7487,  2009,  4180,\n         1037,  2574,  1037,  2023,  5353,  1045,  2572, 15252,  1996,  3189,\n         1998,  3424,  6895, 17585,  2008,  1045,  2089,  2022,  1999,  1037,\n         2597,  2000, 18012,  2017,  1997,  1996,  2569,  9517,  4054,  7091,\n         1037,  2574,  1037,  2023,  5353, 19820,  2626,  1999,  2010,  3661,\n         1996,  2327,  3951,  1998,  7672,  2006,  1996,  2160,  1998,  4001,\n        14814,  2837,  3582,  3841, 17710,  2860,  2006,  9130, 10474,  2012,\n         3841,  3489,  2860,  2030, 10373,  2032,  2012, 23923,  7974, 13578,\n         4183,  8237, 13535,  5358,   102,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\n","output_type":"stream"}]},{"cell_type":"code","source":"print((X_train_tokenized[\"input_ids\"])[0].shape[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GN-3kdzJNCft","outputId":"2c424586-981f-4fd4-a66a-0de382f5ab4a","execution":{"iopub.status.busy":"2022-11-12T12:24:28.329159Z","iopub.execute_input":"2022-11-12T12:24:28.330109Z","iopub.status.idle":"2022-11-12T12:24:28.335820Z","shell.execute_reply.started":"2022-11-12T12:24:28.330050Z","shell.execute_reply":"2022-11-12T12:24:28.334664Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"512\n","output_type":"stream"}]},{"cell_type":"code","source":"train_inputs=X_train_tokenized[\"input_ids\"]","metadata":{"id":"nJoQ58dwbTuU","execution":{"iopub.status.busy":"2022-11-12T12:24:28.337375Z","iopub.execute_input":"2022-11-12T12:24:28.338074Z","iopub.status.idle":"2022-11-12T12:24:28.345887Z","shell.execute_reply.started":"2022-11-12T12:24:28.338031Z","shell.execute_reply":"2022-11-12T12:24:28.344825Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\noutputs = model(**(X_train_tokenized))\n\"\"\"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"nvRavGK1Q6Qg","outputId":"bc7a06fa-27bc-488d-e0f5-0bf82cd946ef","execution":{"iopub.status.busy":"2022-11-12T12:24:28.347370Z","iopub.execute_input":"2022-11-12T12:24:28.347753Z","iopub.status.idle":"2022-11-12T12:24:28.357137Z","shell.execute_reply.started":"2022-11-12T12:24:28.347718Z","shell.execute_reply":"2022-11-12T12:24:28.356086Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"'\\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\\noutputs = model(**(X_train_tokenized))\\n'"},"metadata":{}}]},{"cell_type":"code","source":"## Example of the y-variable (Classes)\n\nprint(train[\"type\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WgPrDjXX9g9","outputId":"f8aa26bf-97c0-4e3f-e2a4-c490d980ccc3","execution":{"iopub.status.busy":"2022-11-12T12:24:28.365851Z","iopub.execute_input":"2022-11-12T12:24:28.366116Z","iopub.status.idle":"2022-11-12T12:24:28.373672Z","shell.execute_reply.started":"2022-11-12T12:24:28.366092Z","shell.execute_reply":"2022-11-12T12:24:28.372556Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"id\n833042063       satire\n832959523       satire\n833039623       satire\n833032367       satire\n814777937       satire\n               ...    \n832908978    reporting\n832910505       satire\n832917532    reporting\n832913653    reporting\n832917778    reporting\nName: type, Length: 433, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"## Encode labels as 0,1,2 satire,opinion,reporting\n\n\nfrom sklearn import preprocessing\n  \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \nprint(train['type'].unique())\n\n# Encode labels in column 'type'.\ntrain['type']= label_encoder.fit_transform(train['type'])\n  \nprint(train['type'].unique())\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNfLV_a4c631","outputId":"e28d33ca-f289-4e7b-81f6-4ce27baac174","execution":{"iopub.status.busy":"2022-11-12T12:24:28.375209Z","iopub.execute_input":"2022-11-12T12:24:28.376342Z","iopub.status.idle":"2022-11-12T12:24:28.387653Z","shell.execute_reply.started":"2022-11-12T12:24:28.376307Z","shell.execute_reply":"2022-11-12T12:24:28.386650Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"['satire' 'opinion' 'reporting']\n[2 0 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_label=train[\"type\"].values","metadata":{"id":"E3zVl4uFcGOh","execution":{"iopub.status.busy":"2022-11-12T12:24:28.388954Z","iopub.execute_input":"2022-11-12T12:24:28.390029Z","iopub.status.idle":"2022-11-12T12:24:28.397359Z","shell.execute_reply.started":"2022-11-12T12:24:28.389992Z","shell.execute_reply":"2022-11-12T12:24:28.396262Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"train_label","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCEBl35hcob8","outputId":"88af3d54-643b-4aff-c9f1-cde8ce8400ae","execution":{"iopub.status.busy":"2022-11-12T12:24:28.398682Z","iopub.execute_input":"2022-11-12T12:24:28.399272Z","iopub.status.idle":"2022-11-12T12:24:28.409765Z","shell.execute_reply.started":"2022-11-12T12:24:28.399235Z","shell.execute_reply":"2022-11-12T12:24:28.408747Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"array([2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"train_labels = torch.tensor(train_label)\n","metadata":{"id":"9sUG2608cqGn","execution":{"iopub.status.busy":"2022-11-12T12:24:28.411292Z","iopub.execute_input":"2022-11-12T12:24:28.412020Z","iopub.status.idle":"2022-11-12T12:24:28.418133Z","shell.execute_reply.started":"2022-11-12T12:24:28.411985Z","shell.execute_reply":"2022-11-12T12:24:28.417390Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9LZ0JrZeQNR","outputId":"d2c7afb7-c201-4a9a-ae08-f47f4627cacd","execution":{"iopub.status.busy":"2022-11-12T12:24:28.419416Z","iopub.execute_input":"2022-11-12T12:24:28.420015Z","iopub.status.idle":"2022-11-12T12:24:28.431220Z","shell.execute_reply.started":"2022-11-12T12:24:28.419980Z","shell.execute_reply":"2022-11-12T12:24:28.430400Z"},"trusted":true},"execution_count":137,"outputs":[{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"tensor([2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1,\n        1])"},"metadata":{}}]},{"cell_type":"code","source":"train_masks=X_train_tokenized['attention_mask']\n","metadata":{"id":"6prLh5SYgiy2","execution":{"iopub.status.busy":"2022-11-12T12:24:28.432816Z","iopub.execute_input":"2022-11-12T12:24:28.433619Z","iopub.status.idle":"2022-11-12T12:24:28.438712Z","shell.execute_reply.started":"2022-11-12T12:24:28.433562Z","shell.execute_reply":"2022-11-12T12:24:28.437490Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"train_masks[0:5]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shGl4X84g0F3","outputId":"db69c218-e90b-4fcd-b6f8-58a2654f604d","execution":{"iopub.status.busy":"2022-11-12T12:24:28.440731Z","iopub.execute_input":"2022-11-12T12:24:28.441533Z","iopub.status.idle":"2022-11-12T12:24:28.449898Z","shell.execute_reply.started":"2022-11-12T12:24:28.441495Z","shell.execute_reply":"2022-11-12T12:24:28.448947Z"},"trusted":true},"execution_count":139,"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]])"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#Creating the DataLoader which will help us to load data into the GPU/CPU\nbatch_size = 2\n\n# Create the DataLoader for our training set.\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","metadata":{"id":"AMHSrCWveR3R","execution":{"iopub.status.busy":"2022-11-12T12:24:28.451388Z","iopub.execute_input":"2022-11-12T12:24:28.451999Z","iopub.status.idle":"2022-11-12T12:24:28.458422Z","shell.execute_reply.started":"2022-11-12T12:24:28.451964Z","shell.execute_reply":"2022-11-12T12:24:28.457802Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"# The Bert-Base Model ","metadata":{}},{"cell_type":"markdown","source":"In this code we use the Pre-trained bert-base-model trained on English Wikepedia Texts to get some contextual representations of the tokens of the training set. The weights are also loaded from the pre-trained model and is fine-tuned to the specific task that we are trying to accomplish namely news type classification. We run training for about 8 epochs to get the classifier.The Bert model has 12 attention heads and 12 Attention layers. The <CLS> token is used for the classification task with a SoftMax layer attached to it. ","metadata":{}},{"cell_type":"code","source":"#Loading the pre-trained BERT model from huggingface library\n\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig\nfrom transformers import RobertaForSequenceClassification\n\n# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \n\n\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", \n    num_labels = 3,   \n    output_attentions = False, \n    output_hidden_states = False, )\n \n\"\"\"\nmodel = RobertaForSequenceClassification.from_pretrained(\n    \"roberta-base\", \n    \n    # Specify number of classes\n    num_labels = 3, \n    # Whether the model returns attentions weights\n    output_attentions = False,\n    # Whether the model returns all hidden-states \n    output_hidden_states = False)\n\"\"\"\n    \n  \n\n# Telling the model to run on GPU\nmodel.cuda()\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513,"referenced_widgets":["2fd423bcb37549fbac67196c0a04cc36","d196ea0fff8349b49f056e71170a0b9f","f48320c1d51e48e280982ef318ddd77f","2c22234b9966431690f6c6336cf54095","ea577aebbad24266aa3fb214eddc3fb1","0a304bb2d2d846f1b20dab41b1a5022e","1060e4f1e31c442dae93ad4677d78751","dceb0f63f9da45b782ca641627846ad8","b109be86a87a417397d969a335b76e3a","eb0476225cfd49f480a19a4c239ff057","850e990ccfaf47b4b5afb62e3bc242e0"]},"id":"ohwworwFhVHr","outputId":"1b7cc25b-1113-4880-96ba-d2862ec39f56","execution":{"iopub.status.busy":"2022-11-12T12:24:28.459841Z","iopub.execute_input":"2022-11-12T12:24:28.460458Z","iopub.status.idle":"2022-11-12T12:24:31.000673Z","shell.execute_reply.started":"2022-11-12T12:24:28.460424Z","shell.execute_reply":"2022-11-12T12:24:30.999591Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\noptimizer = AdamW(model.parameters(),\n                  lr = 3e-5, \n                  eps = 1e-8\n                )","metadata":{"id":"vobf8A6Ki9di","execution":{"iopub.status.busy":"2022-11-12T12:24:31.002052Z","iopub.execute_input":"2022-11-12T12:24:31.002696Z","iopub.status.idle":"2022-11-12T12:24:31.013121Z","shell.execute_reply.started":"2022-11-12T12:24:31.002654Z","shell.execute_reply":"2022-11-12T12:24:31.011992Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n# Number of training epochs (authors recommend between 2 and 4)\nepochs = 8\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)\n#scheduler","metadata":{"id":"xahGt_jQjJyF","execution":{"iopub.status.busy":"2022-11-12T12:24:31.014657Z","iopub.execute_input":"2022-11-12T12:24:31.015771Z","iopub.status.idle":"2022-11-12T12:24:31.023277Z","shell.execute_reply.started":"2022-11-12T12:24:31.015724Z","shell.execute_reply":"2022-11-12T12:24:31.022262Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\n    ","metadata":{"id":"khO7qZJajlB1","execution":{"iopub.status.busy":"2022-11-12T12:24:31.026148Z","iopub.execute_input":"2022-11-12T12:24:31.026578Z","iopub.status.idle":"2022-11-12T12:24:31.034959Z","shell.execute_reply.started":"2022-11-12T12:24:31.026544Z","shell.execute_reply":"2022-11-12T12:24:31.033989Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"#Creating the helper function to have a watch on elapsed time\n\nimport time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n    ","metadata":{"id":"9TlWMwZjkPW9","execution":{"iopub.status.busy":"2022-11-12T12:24:31.036461Z","iopub.execute_input":"2022-11-12T12:24:31.036945Z","iopub.status.idle":"2022-11-12T12:24:31.044784Z","shell.execute_reply.started":"2022-11-12T12:24:31.036911Z","shell.execute_reply":"2022-11-12T12:24:31.043870Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Checking for the GPU\ndevice_name = tf.test.gpu_device_name()\nprint(device_name)\n\n","metadata":{"id":"O8bgWlj7nsGG","execution":{"iopub.status.busy":"2022-11-12T12:24:31.046378Z","iopub.execute_input":"2022-11-12T12:24:31.046827Z","iopub.status.idle":"2022-11-12T12:24:31.060363Z","shell.execute_reply.started":"2022-11-12T12:24:31.046792Z","shell.execute_reply":"2022-11-12T12:24:31.059373Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"/device:GPU:0\n","output_type":"stream"},{"name":"stderr","text":"2022-11-12 12:24:31.052056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 12:24:31.052903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 12:24:31.053475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 12:24:31.054158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 12:24:31.054747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 12:24:31.055224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 14571 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\")","metadata":{"id":"DFihZeYYnx6s","execution":{"iopub.status.busy":"2022-11-12T12:24:31.061750Z","iopub.execute_input":"2022-11-12T12:24:31.062859Z","iopub.status.idle":"2022-11-12T12:24:31.068369Z","shell.execute_reply.started":"2022-11-12T12:24:31.062825Z","shell.execute_reply":"2022-11-12T12:24:31.067713Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"id":"X5cxK4p2n2HV","execution":{"iopub.status.busy":"2022-11-12T12:24:31.071109Z","iopub.execute_input":"2022-11-12T12:24:31.071897Z","iopub.status.idle":"2022-11-12T12:24:31.079352Z","shell.execute_reply.started":"2022-11-12T12:24:31.071860Z","shell.execute_reply":"2022-11-12T12:24:31.078640Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training the Bert Model","metadata":{"id":"NVMBdnMCksEf"}},{"cell_type":"code","source":"import random\n\n# This training code is based on the `run_glue.py` script here:\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n\n%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 100\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n# Get the weight tensor for every class (0,1,2)\ntrain_label_np=np.array(train_label)\n\nno_0=np.sum(train_label_np==0)\nno_1=np.sum(train_label_np==1)\nno_2=np.sum(train_label_np==2)\n\nmax_no = max(no_0,no_1,no_2)\n\nno_0 = max_no/no_0\nno_1 = max_no/no_1       # Weights of each label for the loss function\nno_2 = max_no/no_2\n\nweight_list = [no_0,no_1,no_2]\n#weight_list=[20,20,20]\n\nweights = torch.tensor(weight_list)\nweights=weights.float()\nweights= weights.to(device)\n\n# Store the average loss after each epoch so we can plot them.\nloss_values = []\n\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    total_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to \n    # `train` just changes the *mode*, it doesn't *perform* the training.\n    # `dropout` and `batchnorm` layers behave differently during training\n    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n    model.train()\n\n    # For each batch of training data...\n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 40 batches.\n        if step % 40 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n\n        # Always clear any previously calculated gradients before performing a\n        # backward pass. PyTorch doesn't do this automatically because \n        # accumulating the gradients is \"convenient while training RNNs\". \n        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).\n        # This will return the loss (rather than the model output) because we\n        # have provided the `labels`.\n        # The documentation for this `model` function is here: \n        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n        outputs = model(b_input_ids, \n                    token_type_ids=None, \n                    attention_mask=b_input_mask, \n                    labels=b_labels)\n        \n        # The call to `model` always returns a tuple, so we need to pull the \n        # loss value out of the tuple.\n        logits = outputs.logits\n        \n        #print(logits.dtype)\n        #print(b_labels.dtype)\n        #print(weights.dtype)\n       \n        \n        # Compute your own loss function(to include weights of the classes)\n       \n        #loss=nn.CrossEntropyLoss(weight=weights,reduction=\"mean\")\n        loss=outputs[0]\n        \n        #loss_value=loss(logits,b_labels)\n        \n        \n\n        # Accumulate the training loss over all of the batches so that we can\n        # calculate the average loss at the end. `loss` is a Tensor containing a\n        # single value; the `.item()` function just returns the Python value \n        # from the tensor.\n        total_loss += loss.item()\n\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n\n        # Update the learning rate.\n        scheduler.step()\n\n        # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)            \n    \n    # Store the loss value for plotting the learning curve.\n    loss_values.append(avg_train_loss)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n        \nprint(\"\")\nprint(\"Training complete!\")   ","metadata":{"id":"lroSsUL7khz_","execution":{"iopub.status.busy":"2022-11-12T12:24:31.081628Z","iopub.execute_input":"2022-11-12T12:24:31.081992Z","iopub.status.idle":"2022-11-12T12:28:31.699752Z","shell.execute_reply.started":"2022-11-12T12:24:31.081959Z","shell.execute_reply":"2022-11-12T12:28:31.698679Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"env: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n\n======== Epoch 1 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.63\n  Training epoch took: 0:00:30\n\n======== Epoch 2 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.62\n  Training epoch took: 0:00:30\n\n======== Epoch 3 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.60\n  Training epoch took: 0:00:30\n\n======== Epoch 4 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.61\n  Training epoch took: 0:00:30\n\n======== Epoch 5 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.57\n  Training epoch took: 0:00:30\n\n======== Epoch 6 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.45\n  Training epoch took: 0:00:30\n\n======== Epoch 7 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.28\n  Training epoch took: 0:00:30\n\n======== Epoch 8 / 8 ========\nTraining...\n  Batch    40  of    217.    Elapsed: 0:00:06.\n  Batch    80  of    217.    Elapsed: 0:00:11.\n  Batch   120  of    217.    Elapsed: 0:00:17.\n  Batch   160  of    217.    Elapsed: 0:00:22.\n  Batch   200  of    217.    Elapsed: 0:00:28.\n\n  Average training loss: 0.17\n  Training epoch took: 0:00:30\n\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.memory_stats(device)","metadata":{"id":"o5Ul8wS4t6UG","execution":{"iopub.status.busy":"2022-11-12T12:28:31.701294Z","iopub.execute_input":"2022-11-12T12:28:31.701909Z","iopub.status.idle":"2022-11-12T12:28:31.714045Z","shell.execute_reply.started":"2022-11-12T12:28:31.701870Z","shell.execute_reply":"2022-11-12T12:28:31.713055Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('active.all.allocated', 8103307),\n             ('active.all.current', 2425),\n             ('active.all.freed', 8100882),\n             ('active.all.peak', 2666),\n             ('active.large_pool.allocated', 4240375),\n             ('active.large_pool.current', 900),\n             ('active.large_pool.freed', 4239475),\n             ('active.large_pool.peak', 1060),\n             ('active.small_pool.allocated', 3862932),\n             ('active.small_pool.current', 1525),\n             ('active.small_pool.freed', 3861407),\n             ('active.small_pool.peak', 1727),\n             ('active_bytes.all.allocated', 33701870629376),\n             ('active_bytes.all.current', 5367720960),\n             ('active_bytes.all.freed', 33696502908416),\n             ('active_bytes.all.peak', 6699355648),\n             ('active_bytes.large_pool.allocated', 33595697135616),\n             ('active_bytes.large_pool.current', 5361631232),\n             ('active_bytes.large_pool.freed', 33590335504384),\n             ('active_bytes.large_pool.peak', 6674186240),\n             ('active_bytes.small_pool.allocated', 106173493760),\n             ('active_bytes.small_pool.current', 6089728),\n             ('active_bytes.small_pool.freed', 106167404032),\n             ('active_bytes.small_pool.peak', 25994240),\n             ('allocated_bytes.all.allocated', 33701870629376),\n             ('allocated_bytes.all.current', 5367720960),\n             ('allocated_bytes.all.freed', 33696502908416),\n             ('allocated_bytes.all.peak', 6699355648),\n             ('allocated_bytes.large_pool.allocated', 33595697135616),\n             ('allocated_bytes.large_pool.current', 5361631232),\n             ('allocated_bytes.large_pool.freed', 33590335504384),\n             ('allocated_bytes.large_pool.peak', 6674186240),\n             ('allocated_bytes.small_pool.allocated', 106173493760),\n             ('allocated_bytes.small_pool.current', 6089728),\n             ('allocated_bytes.small_pool.freed', 106167404032),\n             ('allocated_bytes.small_pool.peak', 25994240),\n             ('allocation.all.allocated', 8103307),\n             ('allocation.all.current', 2425),\n             ('allocation.all.freed', 8100882),\n             ('allocation.all.peak', 2666),\n             ('allocation.large_pool.allocated', 4240375),\n             ('allocation.large_pool.current', 900),\n             ('allocation.large_pool.freed', 4239475),\n             ('allocation.large_pool.peak', 1060),\n             ('allocation.small_pool.allocated', 3862932),\n             ('allocation.small_pool.current', 1525),\n             ('allocation.small_pool.freed', 3861407),\n             ('allocation.small_pool.peak', 1727),\n             ('inactive_split.all.allocated', 3957277),\n             ('inactive_split.all.current', 237),\n             ('inactive_split.all.freed', 3957040),\n             ('inactive_split.all.peak', 263),\n             ('inactive_split.large_pool.allocated', 2140612),\n             ('inactive_split.large_pool.current', 155),\n             ('inactive_split.large_pool.freed', 2140457),\n             ('inactive_split.large_pool.peak', 172),\n             ('inactive_split.small_pool.allocated', 1816665),\n             ('inactive_split.small_pool.current', 82),\n             ('inactive_split.small_pool.freed', 1816583),\n             ('inactive_split.small_pool.peak', 94),\n             ('inactive_split_bytes.all.allocated', 19146740194816),\n             ('inactive_split_bytes.all.current', 302978048),\n             ('inactive_split_bytes.all.freed', 19146437216768),\n             ('inactive_split_bytes.all.peak', 418124288),\n             ('inactive_split_bytes.large_pool.allocated', 19009016954880),\n             ('inactive_split_bytes.large_pool.current', 300679168),\n             ('inactive_split_bytes.large_pool.freed', 19008716275712),\n             ('inactive_split_bytes.large_pool.peak', 411041792),\n             ('inactive_split_bytes.small_pool.allocated', 137723239936),\n             ('inactive_split_bytes.small_pool.current', 2298880),\n             ('inactive_split_bytes.small_pool.freed', 137720941056),\n             ('inactive_split_bytes.small_pool.peak', 8321536),\n             ('max_split_size', -1),\n             ('num_alloc_retries', 0),\n             ('num_ooms', 0),\n             ('oversize_allocations.allocated', 0),\n             ('oversize_allocations.current', 0),\n             ('oversize_allocations.freed', 0),\n             ('oversize_allocations.peak', 0),\n             ('oversize_segments.allocated', 0),\n             ('oversize_segments.current', 0),\n             ('oversize_segments.freed', 0),\n             ('oversize_segments.peak', 0),\n             ('reserved_bytes.all.allocated', 9858711552),\n             ('reserved_bytes.all.current', 7052722176),\n             ('reserved_bytes.all.freed', 2805989376),\n             ('reserved_bytes.all.peak', 7052722176),\n             ('reserved_bytes.large_pool.allocated', 9774825472),\n             ('reserved_bytes.large_pool.current', 7019167744),\n             ('reserved_bytes.large_pool.freed', 2755657728),\n             ('reserved_bytes.large_pool.peak', 7019167744),\n             ('reserved_bytes.small_pool.allocated', 83886080),\n             ('reserved_bytes.small_pool.current', 33554432),\n             ('reserved_bytes.small_pool.freed', 50331648),\n             ('reserved_bytes.small_pool.peak', 33554432),\n             ('segment.all.allocated', 417),\n             ('segment.all.current', 283),\n             ('segment.all.freed', 134),\n             ('segment.all.peak', 283),\n             ('segment.large_pool.allocated', 377),\n             ('segment.large_pool.current', 267),\n             ('segment.large_pool.freed', 110),\n             ('segment.large_pool.peak', 267),\n             ('segment.small_pool.allocated', 40),\n             ('segment.small_pool.current', 16),\n             ('segment.small_pool.freed', 24),\n             ('segment.small_pool.peak', 16)])"},"metadata":{}}]},{"cell_type":"code","source":"X_test=X_test.tolist()","metadata":{"id":"F6XreQXiuDy3","execution":{"iopub.status.busy":"2022-11-12T12:28:31.715445Z","iopub.execute_input":"2022-11-12T12:28:31.716009Z","iopub.status.idle":"2022-11-12T12:28:31.724481Z","shell.execute_reply.started":"2022-11-12T12:28:31.715970Z","shell.execute_reply":"2022-11-12T12:28:31.723411Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"X_test[0]","metadata":{"id":"mNpNMCrDt-Vs","execution":{"iopub.status.busy":"2022-11-12T12:28:31.725920Z","iopub.execute_input":"2022-11-12T12:28:31.726649Z","iopub.status.idle":"2022-11-12T12:28:31.736047Z","shell.execute_reply.started":"2022-11-12T12:28:31.726592Z","shell.execute_reply":"2022-11-12T12:28:31.734764Z"},"trusted":true},"execution_count":152,"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"'flashback howard dean incorrectly predicts mueller will indict jared kushner  appearing november 5th  on msnbc former gov howard dean dvt wrongly predicted special counsel robert mueller would indict president donald trumps soninlaw jared kushner for money laundering as part of his investigation into possible collusion between the trump campaign and russia during the  presidential election we believe we may well have a criminal in the white house howard dean told host keir simmonscertainly he has a special interest in the trump family and their investments and we think there is substantial likelihood that he has laundered money that is what his associates have been charged with and so this is a very serious matteri do not think this about politics actually dean described mueller as a straight shooter and then predicted that he would target kushner after indicting former national security adviser michael flynn and his son michael flynn jrthe next step is going to be the trump family itself dean continued i expect that there is a good likelihood jared kushner will be indicted for money laundering and then we are going to have to see how far the russian involvement goes this is serious business these people are undermining our democracy he added and it appears to me what bob mueller is investigating is whether the president of the united states engaged with a foreign power in order to get where he got that is a very serious matter for this country on friday mueller delivered his russia probe report to attorney general william barr who stated he will provide congressional leaders with his account of the findings as early as the weekend a senior justice department official said the special counsel will not bring further indictments as part of his probe  '"},"metadata":{}}]},{"cell_type":"code","source":"X_test_tokenized=tokenizer(X_test,padding=True,truncation=True,return_tensors=\"pt\")\n","metadata":{"id":"WYH2FDye15IX","execution":{"iopub.status.busy":"2022-11-12T12:28:31.737544Z","iopub.execute_input":"2022-11-12T12:28:31.738041Z","iopub.status.idle":"2022-11-12T12:28:33.603192Z","shell.execute_reply.started":"2022-11-12T12:28:31.738007Z","shell.execute_reply":"2022-11-12T12:28:33.602234Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"print((X_test_tokenized[\"input_ids\"])[0])\n","metadata":{"id":"pbeUTlzu2QKc","execution":{"iopub.status.busy":"2022-11-12T12:28:33.604731Z","iopub.execute_input":"2022-11-12T12:28:33.605093Z","iopub.status.idle":"2022-11-12T12:28:33.615006Z","shell.execute_reply.started":"2022-11-12T12:28:33.605056Z","shell.execute_reply":"2022-11-12T12:28:33.613744Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"tensor([  101, 21907,  4922,  4670, 19721, 16014,  2015, 26774,  2097, 27427,\n         2594,  2102,  8334, 13970,  4095,  3678,  6037,  2281,  4833,  2006,\n         5796, 28957,  2280, 18079,  4922,  4670,  1040,  2615,  2102, 29116,\n        10173,  2569,  9517,  2728, 26774,  2052, 27427,  2594,  2102,  2343,\n         6221,  8398,  2015,  2365,  2378, 14919,  8334, 13970,  4095,  3678,\n         2005,  2769, 28289,  2004,  2112,  1997,  2010,  4812,  2046,  2825,\n         8902, 24117,  2090,  1996,  8398,  3049,  1998,  3607,  2076,  1996,\n         4883,  2602,  2057,  2903,  2057,  2089,  2092,  2031,  1037,  4735,\n         1999,  1996,  2317,  2160,  4922,  4670,  2409,  3677, 26679,  2099,\n        13672, 17119, 18249,  2135,  2002,  2038,  1037,  2569,  3037,  1999,\n         1996,  8398,  2155,  1998,  2037, 10518,  1998,  2057,  2228,  2045,\n         2003,  6937, 16593,  2008,  2002,  2038, 21360, 11563,  2098,  2769,\n         2008,  2003,  2054,  2010,  9228,  2031,  2042,  5338,  2007,  1998,\n         2061,  2023,  2003,  1037,  2200,  3809,  3043,  2072,  2079,  2025,\n         2228,  2023,  2055,  4331,  2941,  4670,  2649, 26774,  2004,  1037,\n         3442, 13108,  1998,  2059, 10173,  2008,  2002,  2052,  4539, 13970,\n         4095,  3678,  2044, 27427,  2594,  3436,  2280,  2120,  3036, 11747,\n         2745, 13259,  1998,  2010,  2365,  2745, 13259,  3781, 10760,  2279,\n         3357,  2003,  2183,  2000,  2022,  1996,  8398,  2155,  2993,  4670,\n         2506,  1045,  5987,  2008,  2045,  2003,  1037,  2204, 16593,  8334,\n        13970,  4095,  3678,  2097,  2022, 21801,  2005,  2769, 28289,  1998,\n         2059,  2057,  2024,  2183,  2000,  2031,  2000,  2156,  2129,  2521,\n         1996,  2845,  6624,  3632,  2023,  2003,  3809,  2449,  2122,  2111,\n         2024,  2104, 25300,  3070,  2256,  7072,  2002,  2794,  1998,  2009,\n         3544,  2000,  2033,  2054,  3960, 26774,  2003, 11538,  2003,  3251,\n         1996,  2343,  1997,  1996,  2142,  2163,  5117,  2007,  1037,  3097,\n         2373,  1999,  2344,  2000,  2131,  2073,  2002,  2288,  2008,  2003,\n         1037,  2200,  3809,  3043,  2005,  2023,  2406,  2006,  5958, 26774,\n         5359,  2010,  3607, 15113,  3189,  2000,  4905,  2236,  2520, 19820,\n         2040,  3090,  2002,  2097,  3073,  7740,  4177,  2007,  2010,  4070,\n         1997,  1996,  9556,  2004,  2220,  2004,  1996,  5353,  1037,  3026,\n         3425,  2533,  2880,  2056,  1996,  2569,  9517,  2097,  2025,  3288,\n         2582, 24265,  2015,  2004,  2112,  1997,  2010, 15113,   102,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\n","output_type":"stream"}]},{"cell_type":"code","source":"test_inputs=X_test_tokenized[\"input_ids\"]\n","metadata":{"id":"WtTlf6RO2b3j","execution":{"iopub.status.busy":"2022-11-12T12:28:33.616542Z","iopub.execute_input":"2022-11-12T12:28:33.617003Z","iopub.status.idle":"2022-11-12T12:28:33.631977Z","shell.execute_reply.started":"2022-11-12T12:28:33.616967Z","shell.execute_reply":"2022-11-12T12:28:33.627440Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"test_masks=X_test_tokenized['attention_mask']\n","metadata":{"id":"1WqQU_DT2nUG","execution":{"iopub.status.busy":"2022-11-12T12:28:33.633569Z","iopub.execute_input":"2022-11-12T12:28:33.633948Z","iopub.status.idle":"2022-11-12T12:28:33.639525Z","shell.execute_reply.started":"2022-11-12T12:28:33.633913Z","shell.execute_reply":"2022-11-12T12:28:33.638425Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"# Predicting on the Validation Set","metadata":{}},{"cell_type":"code","source":"# Set the batch size.  \nbatch_size = 2  \n\n# Create the DataLoader.\nprediction_data = TensorDataset(test_inputs, test_masks)\n\nprediction_dataloader = DataLoader(prediction_data,shuffle=False, batch_size=batch_size)\n\nprint(\"No of test sentences\",len(X_test))","metadata":{"id":"cjTPIYoB2xYP","execution":{"iopub.status.busy":"2022-11-12T12:28:33.641517Z","iopub.execute_input":"2022-11-12T12:28:33.647159Z","iopub.status.idle":"2022-11-12T12:28:33.664129Z","shell.execute_reply.started":"2022-11-12T12:28:33.647112Z","shell.execute_reply":"2022-11-12T12:28:33.660630Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"No of test sentences 83\n","output_type":"stream"}]},{"cell_type":"code","source":"## Predicting on the Validation set\n\n#Evaluating our model on the test set\n\n#Prediction on test set\n\nprint('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n\n# Put model in evaluation mode\nmodel.eval()\n\npredictions=[]\n\nfor batch in prediction_dataloader:\n  # Add batch to GPU\n\n  batch = tuple(t.to(device) for t in batch)\n  \n  # Unpack the inputs from our dataloader\n  b_input_ids, b_input_mask = batch\n  \n  # Telling the model not to compute or store gradients, saving memory and \n  # speeding up prediction\n\n  with torch.no_grad():\n      # Forward pass, calculate logit predictions\n      outputs = model(b_input_ids, token_type_ids=None, \n                      attention_mask=b_input_mask)\n\n  logits = outputs[0]\n\n  # Move logits and labels to CPU\n  logits = logits.detach().cpu().numpy()\n  \n  # Store predictions and true labels\n  predictions.append(logits)\n","metadata":{"id":"qV3sPUXa3Wbk","execution":{"iopub.status.busy":"2022-11-12T12:28:33.665231Z","iopub.execute_input":"2022-11-12T12:28:33.665563Z","iopub.status.idle":"2022-11-12T12:28:35.260941Z","shell.execute_reply.started":"2022-11-12T12:28:33.665532Z","shell.execute_reply":"2022-11-12T12:28:35.259976Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"Predicting labels for 83 test sentences...\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions","metadata":{"id":"Vbci1KZo45FP","execution":{"iopub.status.busy":"2022-11-12T12:28:35.262418Z","iopub.execute_input":"2022-11-12T12:28:35.262789Z","iopub.status.idle":"2022-11-12T12:28:35.278799Z","shell.execute_reply.started":"2022-11-12T12:28:35.262749Z","shell.execute_reply":"2022-11-12T12:28:35.277582Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"[array([[-0.41775686,  0.11189505,  0.0826977 ],\n        [-2.519041  ,  1.3257946 ,  1.2903202 ]], dtype=float32),\n array([[-2.125192  ,  1.1661922 ,  1.1847858 ],\n        [-1.5541991 ,  1.4813188 ,  0.17173551]], dtype=float32),\n array([[-1.4593611 ,  1.1412126 ,  0.10558085],\n        [-0.5473129 ,  0.19493614,  0.0763908 ]], dtype=float32),\n array([[-2.263418 ,  1.2279042,  1.2296252],\n        [-2.0402064,  1.072484 ,  1.1377082]], dtype=float32),\n array([[-2.215379 ,  1.3910235,  0.9797152],\n        [-2.443019 ,  1.3671554,  1.2740847]], dtype=float32),\n array([[-2.2742603,  1.1852673,  1.3167689],\n        [-2.2773387,  1.3456517,  1.0155753]], dtype=float32),\n array([[ 5.580712 , -2.0270498, -3.678043 ],\n        [-2.3739486,  1.266412 ,  1.2665095]], dtype=float32),\n array([[-2.2085266 ,  1.3779161 ,  0.9420226 ],\n        [-1.3465374 ,  1.4811412 ,  0.02207996]], dtype=float32),\n array([[-2.579902  ,  1.4854283 ,  1.1201614 ],\n        [-2.1096776 ,  1.3426871 ,  0.83612484]], dtype=float32),\n array([[-2.491346  ,  1.4078884 ,  1.2140551 ],\n        [-1.9995466 ,  1.2229455 ,  0.72153175]], dtype=float32),\n array([[-1.4190184 ,  1.4992442 ,  0.06306707],\n        [-2.3560266 ,  1.4376934 ,  1.0324454 ]], dtype=float32),\n array([[-1.5175058 ,  1.4464146 ,  0.13027602],\n        [-1.6965154 ,  0.9174658 ,  0.6264001 ]], dtype=float32),\n array([[-1.3160368 ,  0.69923085,  0.85558903],\n        [-1.3708442 ,  1.4879531 ,  0.03638382]], dtype=float32),\n array([[-0.34097683,  0.01304068, -0.00708604],\n        [-2.4198616 ,  1.3020567 ,  1.3037766 ]], dtype=float32),\n array([[-1.3651012 ,  1.1158698 ,  0.07725118],\n        [-2.3371003 ,  1.4447646 ,  1.0045161 ]], dtype=float32),\n array([[-2.061863  ,  1.3034526 ,  0.872858  ],\n        [-1.4146419 ,  1.4907731 ,  0.05952311]], dtype=float32),\n array([[ 4.788965 , -1.4571865, -3.5697877],\n        [ 5.310055 , -1.8139912, -3.7835865]], dtype=float32),\n array([[-1.9901634 ,  1.2052311 ,  0.65042454],\n        [-1.5876353 ,  1.3653566 ,  0.24838562]], dtype=float32),\n array([[-2.4351194,  1.4771405,  1.030481 ],\n        [-2.072572 ,  1.1113757,  1.2395811]], dtype=float32),\n array([[-1.420767  ,  1.500114  ,  0.06434035],\n        [-1.5297592 ,  1.4817604 ,  0.1202065 ]], dtype=float32),\n array([[-2.2651849,  1.1548879,  1.2257795],\n        [-2.3663123,  1.3310138,  1.2285596]], dtype=float32),\n array([[-0.26722524,  0.8881521 , -0.8662548 ],\n        [-0.6255807 ,  0.22451253,  0.06574114]], dtype=float32),\n array([[-1.3454952 ,  0.95457715,  0.01437368],\n        [-2.494438  ,  1.352268  ,  1.2721927 ]], dtype=float32),\n array([[-2.560534 ,  1.3910831,  1.2681072],\n        [-2.5139568,  1.4503831,  1.16322  ]], dtype=float32),\n array([[-1.9655511,  1.1860819,  0.722651 ],\n        [-1.9885291,  1.0330281,  1.1474205]], dtype=float32),\n array([[-0.8765002 ,  0.40499184,  0.37252578],\n        [-1.5352983 ,  1.4621229 ,  0.16121683]], dtype=float32),\n array([[-1.339848  ,  1.4793963 ,  0.01891502],\n        [-2.0287073 ,  1.3019814 ,  0.8308464 ]], dtype=float32),\n array([[-2.0706992 ,  1.3070831 ,  0.7641303 ],\n        [-2.35737   ,  1.4274443 ,  0.99151707]], dtype=float32),\n array([[-0.47791442,  0.13233662,  0.06749605],\n        [-2.3022733 ,  1.3997043 ,  1.0265276 ]], dtype=float32),\n array([[-2.122328  ,  1.3382428 ,  0.82670134],\n        [-0.65067697,  0.2947649 ,  0.13148724]], dtype=float32),\n array([[-2.3570201 ,  1.2632858 ,  1.3031921 ],\n        [-1.6702265 ,  1.4602915 ,  0.24131174]], dtype=float32),\n array([[-2.0746355 ,  1.3317183 ,  0.77967745],\n        [-2.489145  ,  1.4396607 ,  1.1619132 ]], dtype=float32),\n array([[ 5.593149 , -2.0593264, -3.5860806],\n        [-2.4381318,  1.2682099,  1.2956512]], dtype=float32),\n array([[-0.66924614,  0.37062082,  0.05204609],\n        [-1.3504128 ,  1.4823158 ,  0.02600142]], dtype=float32),\n array([[-0.36572954, -0.01520911,  0.02761035],\n        [-1.4976143 ,  1.4991289 ,  0.11446972]], dtype=float32),\n array([[-1.6252437 ,  1.3491175 ,  0.04675205],\n        [-1.8826919 ,  0.9632073 ,  1.142604  ]], dtype=float32),\n array([[-1.3304561 ,  0.66519797,  0.5478164 ],\n        [-1.5317293 ,  1.3153324 ,  0.17089547]], dtype=float32),\n array([[-1.8376988 ,  1.747366  ,  0.05032109],\n        [-1.3965882 ,  1.5042776 , -0.29275805]], dtype=float32),\n array([[-1.4327677 ,  1.4919921 ,  0.07649275],\n        [-1.0813344 ,  1.3141857 , -0.4502069 ]], dtype=float32),\n array([[-2.2401583,  1.1696374,  1.263443 ],\n        [ 5.618147 , -2.069143 , -3.62941  ]], dtype=float32),\n array([[-1.8435733 ,  1.1182922 ,  0.50663906],\n        [-2.3391724 ,  1.2602696 ,  1.286014  ]], dtype=float32),\n array([[-1.9629287,  1.1711031,  0.7620997]], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"pred_labels=[]\nfor i in range(len(predictions)):\n  \n  # The predictions for this batch are a 3-column ndarray (one column for \"0\" \n  # ,one column for \"1\",one for \"2\"). Pick the label with the highest value and turn this\n  # in to a list of 0s,1s,2s.\n\n  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n  pred_labels.append(pred_labels_i)\n\n\n","metadata":{"id":"fgAfAt2t45tv","execution":{"iopub.status.busy":"2022-11-12T12:28:35.280386Z","iopub.execute_input":"2022-11-12T12:28:35.281439Z","iopub.status.idle":"2022-11-12T12:28:35.288421Z","shell.execute_reply.started":"2022-11-12T12:28:35.281392Z","shell.execute_reply":"2022-11-12T12:28:35.287294Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"pred_labels","metadata":{"id":"nJjOqcbD66Sa","execution":{"iopub.status.busy":"2022-11-12T12:28:35.289889Z","iopub.execute_input":"2022-11-12T12:28:35.290517Z","iopub.status.idle":"2022-11-12T12:28:35.317898Z","shell.execute_reply.started":"2022-11-12T12:28:35.290477Z","shell.execute_reply":"2022-11-12T12:28:35.316961Z"},"trusted":true},"execution_count":161,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"[array([1, 1]),\n array([2, 1]),\n array([1, 1]),\n array([2, 2]),\n array([1, 1]),\n array([2, 1]),\n array([0, 2]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([2, 1]),\n array([1, 2]),\n array([1, 1]),\n array([1, 1]),\n array([0, 0]),\n array([1, 1]),\n array([1, 2]),\n array([1, 1]),\n array([2, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 2]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([2, 1]),\n array([1, 1]),\n array([0, 2]),\n array([1, 1]),\n array([2, 1]),\n array([1, 2]),\n array([1, 1]),\n array([1, 1]),\n array([1, 1]),\n array([2, 0]),\n array([1, 2]),\n array([1])]"},"metadata":{}}]},{"cell_type":"code","source":"flat_predictions = [item for sublist in predictions for item in sublist]\nflat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n\nflat_predictions","metadata":{"id":"kd4fOlIB7Ei9","execution":{"iopub.status.busy":"2022-11-12T12:28:35.319009Z","iopub.execute_input":"2022-11-12T12:28:35.319284Z","iopub.status.idle":"2022-11-12T12:28:35.339672Z","shell.execute_reply.started":"2022-11-12T12:28:35.319258Z","shell.execute_reply":"2022-11-12T12:28:35.338051Z"},"trusted":true},"execution_count":162,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 2,\n       1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 2, 1])"},"metadata":{}}]},{"cell_type":"code","source":"train.head(10)","metadata":{"id":"GKBJDSabCbbo","execution":{"iopub.status.busy":"2022-11-12T12:28:35.342343Z","iopub.execute_input":"2022-11-12T12:28:35.343043Z","iopub.status.idle":"2022-11-12T12:28:35.363670Z","shell.execute_reply.started":"2022-11-12T12:28:35.342968Z","shell.execute_reply":"2022-11-12T12:28:35.362255Z"},"trusted":true},"execution_count":163,"outputs":[{"execution_count":163,"output_type":"execute_result","data":{"text/plain":"                                                        text  type\nid                                                                \n833042063  chelsea handler admits she is very sexually at...     2\n832959523  how theresa may botched  those were the times…...     2\n833039623  robert mueller iii rests his casedems never wi...     2\n833032367  robert mueller not recommending any more indic...     2\n814777937  the far right is trying to coopt the yellow ve...     2\n821744708  special place in hell for those who promoted b...     2\n833036489  bill maher says he doesnt need mueller report ...     2\n707566605  madagascar outbreak it is inevitable the plagu...     0\n708561738  how do you like paying for sexual harassment s...     2\n782086447  former apostolic nuncio to the united states a...     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>833042063</th>\n      <td>chelsea handler admits she is very sexually at...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>832959523</th>\n      <td>how theresa may botched  those were the times…...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>833039623</th>\n      <td>robert mueller iii rests his casedems never wi...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>833032367</th>\n      <td>robert mueller not recommending any more indic...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>814777937</th>\n      <td>the far right is trying to coopt the yellow ve...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>821744708</th>\n      <td>special place in hell for those who promoted b...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>833036489</th>\n      <td>bill maher says he doesnt need mueller report ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>707566605</th>\n      <td>madagascar outbreak it is inevitable the plagu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>708561738</th>\n      <td>how do you like paying for sexual harassment s...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>782086447</th>\n      <td>former apostolic nuncio to the united states a...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head(7)","metadata":{"id":"lbErxG5p7def","execution":{"iopub.status.busy":"2022-11-12T12:28:35.366435Z","iopub.execute_input":"2022-11-12T12:28:35.367043Z","iopub.status.idle":"2022-11-12T12:28:35.379620Z","shell.execute_reply.started":"2022-11-12T12:28:35.367003Z","shell.execute_reply":"2022-11-12T12:28:35.378329Z"},"trusted":true},"execution_count":164,"outputs":[{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"                                                        text\nid                                                          \n833024133  flashback howard dean incorrectly predicts mue...\n814371058  brexit nigerians in london hope for split  bri...\n815858385  british yellow vest who called proeu mp a nazi...\n832941978  adam schiff rejects reports that mueller indic...\n833021113  roger stone associate jerome corsi celebrates ...\n833067493  don trump jr uses maury povich paternity meme ...\n813552066  you insult us ambassador woody johnson flagran...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>833024133</th>\n      <td>flashback howard dean incorrectly predicts mue...</td>\n    </tr>\n    <tr>\n      <th>814371058</th>\n      <td>brexit nigerians in london hope for split  bri...</td>\n    </tr>\n    <tr>\n      <th>815858385</th>\n      <td>british yellow vest who called proeu mp a nazi...</td>\n    </tr>\n    <tr>\n      <th>832941978</th>\n      <td>adam schiff rejects reports that mueller indic...</td>\n    </tr>\n    <tr>\n      <th>833021113</th>\n      <td>roger stone associate jerome corsi celebrates ...</td>\n    </tr>\n    <tr>\n      <th>833067493</th>\n      <td>don trump jr uses maury povich paternity meme ...</td>\n    </tr>\n    <tr>\n      <th>813552066</th>\n      <td>you insult us ambassador woody johnson flagran...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 2  \n\n# Create the DataLoader.\ntrain_prediction_data = TensorDataset(train_inputs, train_masks)\n\n\ntrain_prediction_dataloader = DataLoader(train_prediction_data, shuffle=False, batch_size=batch_size)\n\nprint(\"No of train sentences\",len(X_train))\n","metadata":{"id":"i78oEiC_CSbu","execution":{"iopub.status.busy":"2022-11-12T12:28:35.381382Z","iopub.execute_input":"2022-11-12T12:28:35.381849Z","iopub.status.idle":"2022-11-12T12:28:35.388206Z","shell.execute_reply.started":"2022-11-12T12:28:35.381810Z","shell.execute_reply":"2022-11-12T12:28:35.386936Z"},"trusted":true},"execution_count":165,"outputs":[{"name":"stdout","text":"No of train sentences 433\n","output_type":"stream"}]},{"cell_type":"code","source":"train_inputs[0]","metadata":{"id":"s9TOxE0tGuHU","execution":{"iopub.status.busy":"2022-11-12T12:28:35.390094Z","iopub.execute_input":"2022-11-12T12:28:35.390633Z","iopub.status.idle":"2022-11-12T12:28:35.404660Z","shell.execute_reply.started":"2022-11-12T12:28:35.390577Z","shell.execute_reply":"2022-11-12T12:28:35.403114Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  9295, 28213, 14456,  2016,  2003,  2200, 12581,  6296,  2000,\n         2728, 26774,  2521,  2571,  6199,  2272, 10265, 10087,  9295, 28213,\n         5292,  4914,  2016,  2003,  2200, 12581,  6296,  2000,  8495,  2569,\n         9517,  2728, 26774,  2074,  3178,  2044,  2002,  5531,  2010,  4812,\n         2046,  4011,  8902, 24117,  2090,  3607,  1998,  6221,  8398,  4883,\n         3049,  2006,  5958,  3944,  1996,  3425,  2533,  2623,  2008, 26774,\n         2018,  5531,  2010,  4812,  2046,  1996,  3043,  1998,  2008,  2002,\n         2052,  2025,  2022, 16755,  2075,  2151,  2062, 24265,  2114,  8398,\n         2030,  3087,  2842,  2920,  1999,  2010,  3049,  2664,  2750,  1996,\n         3635,  1997, 10520,  2371,  2011,  1996,  3484,  2006,  1996,  5365,\n         2187,  9295, 28213,  4914,  2008,  2014, 17418,  2007,  1996,  2095,\n        11614, 12478,  2089,  2031,  2042,  2138,  2016,  2179,  2032, 12581,\n         8702,  2065,  1045,  2572,  2108,  3294,  7481,  1045,  2572,  2200,\n        12581,  6296,  2000,  2728, 26774,  2016,  2626,  2006, 10474,  1045,\n         2113,  2009,  2003,  2025,  3214,  2000,  2022,  2021,  2008, 18629,\n         2025,  2812,  1045,  2097,  2025,  6865,  1037, 13082,  1997,  2032,\n         2682,  2026,  2793,  2065,  1045,  2572,  2108,  3294,  7481,  1045,\n         2572,  2200, 12581,  6296,  2000,  2728, 26774,  1045,  2113,  2009,\n         2003,  2025,  3214,  2000,  2022,  2021,  2008, 18629,  2025,  2812,\n         1045,  2097,  2025,  6865,  1037, 13082,  1997,  2032,  2682,  2026,\n         2793,  9295, 28213,  9295, 11774,  3917,  2233,  2197,  3204,  1996,\n         3478, 20907,  2831,  2265,  3677,  6257, 26774,  1037,  3407, 10113,\n         2154,  2096, 14026,  3246,  2008,  2002,  2052,  2574, 27427,  2594,\n         2102,  1996,  2343,  2365,  6221,  8398,  3781,  2006,  3715,  1997,\n         2845,  8902, 24117,  2030,  2070,  3361, 28616,  3207,  4168, 27869,\n         3407, 10113,  2154,  2000,  2728, 26774,  1998,  2005,  2032,  3228,\n         2010,  2345,  3123,  2000,  6221, 24456,  2361,  3781,  2016,  2626,\n         2008,  2052,  2191,  2023,  6209,  2428,  4175, 26774,  2015,  2345,\n         3189,  5292,  2025,  2664,  2042,  2207,  2348,  4905,  2236,  2520,\n        19820,  2056,  2006,  5958,  2008,  2002,  2071,  7487,  2009,  4180,\n         1037,  2574,  1037,  2023,  5353,  1045,  2572, 15252,  1996,  3189,\n         1998,  3424,  6895, 17585,  2008,  1045,  2089,  2022,  1999,  1037,\n         2597,  2000, 18012,  2017,  1997,  1996,  2569,  9517,  4054,  7091,\n         1037,  2574,  1037,  2023,  5353, 19820,  2626,  1999,  2010,  3661,\n         1996,  2327,  3951,  1998,  7672,  2006,  1996,  2160,  1998,  4001,\n        14814,  2837,  3582,  3841, 17710,  2860,  2006,  9130, 10474,  2012,\n         3841,  3489,  2860,  2030, 10373,  2032,  2012, 23923,  7974, 13578,\n         4183,  8237, 13535,  5358,   102,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Looking at the Train Set Predictions","metadata":{}},{"cell_type":"code","source":"## Predicting on the Training set\n\n#Evaluating our final model on the training set\n\n#Prediction on training set\n\nprint('Predicting labels for {:,} training sentences...'.format(len(train_inputs)))\n\n# Put model in evaluation mode\nmodel.eval()\n\ntrain_predictions=[]\n\nfor batch in train_prediction_dataloader:\n  # Add batch to GPU\n\n  batch = tuple(t.to(device) for t in batch)\n  \n  # Unpack the inputs from our dataloader\n  b_input_ids, b_input_mask = batch\n  \n  \n  # Telling the model not to compute or store gradients, saving memory and \n  # speeding up prediction\n\n  with torch.no_grad():\n      # Forward pass, calculate logit predictions\n      outputs = model(b_input_ids, token_type_ids=None, \n                      attention_mask=b_input_mask)\n\n  logits = outputs[0]\n\n  # Move logits and labels to CPU\n  logits = logits.detach().cpu().numpy()\n  \n  # Store predictions and true labels\n  train_predictions.append(logits)\n\n","metadata":{"id":"yLBMz-16G6c_","execution":{"iopub.status.busy":"2022-11-12T12:28:35.406011Z","iopub.execute_input":"2022-11-12T12:28:35.406516Z","iopub.status.idle":"2022-11-12T12:28:43.622625Z","shell.execute_reply.started":"2022-11-12T12:28:35.406481Z","shell.execute_reply":"2022-11-12T12:28:43.621639Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"Predicting labels for 433 training sentences...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(b_input_ids)","metadata":{"id":"u5E_j_jDKSdh","execution":{"iopub.status.busy":"2022-11-12T12:28:43.624055Z","iopub.execute_input":"2022-11-12T12:28:43.624797Z","iopub.status.idle":"2022-11-12T12:28:43.641544Z","shell.execute_reply.started":"2022-11-12T12:28:43.624760Z","shell.execute_reply":"2022-11-12T12:28:43.640643Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"tensor([[  101,  3189,  2053,  2047, 24265,  2097,  2272,  2013,  2569,  9517,\n          2728, 26774,  2015, 15113,  2053,  2047, 24265,  2097,  2272,  2013,\n          2569,  9517,  2728, 26774,  2015,  3607, 15113,  2044,  2002,  7864,\n          2010,  2345,  3189,  2000,  4905,  2236,  2520, 19820,  3674, 13307,\n          2024,  7316,  1037,  3026,  3425,  2533,  2880,  2409,  1996,  2899,\n          2695,  2008, 26774,  5292,  2025,  6749,  2151,  2582, 24265,  1996,\n          4812,  2003,  3143,  3425,  2533,  3764, 26760, 20778, 14884,  2072,\n         13970,  5051,  2278,  2409,  1996,  3780,  1996, 26774, 15113,  2387,\n          2195,  2306,  8398,  8753, 21801,  2021,  2025,  8398,  2155,  2030,\n          8398,  2370,  2070,  3862,  3275,  2040,  2031, 12254,  5905,  1999,\n          3715, 29217,  2013, 26774,  2015,  4812,  2024,  8398,  2280,  3167,\n          4905,  2745,  9946,  8398,  2280,  3049,  3472,  2703, 24951, 13028,\n          1998,  2280,  2317,  2160,  2120,  3036, 11747,  2745, 13259,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_inputs[432])","metadata":{"id":"6ZG_6S-GKXYG","execution":{"iopub.status.busy":"2022-11-12T12:28:43.643022Z","iopub.execute_input":"2022-11-12T12:28:43.643400Z","iopub.status.idle":"2022-11-12T12:28:43.652950Z","shell.execute_reply.started":"2022-11-12T12:28:43.643364Z","shell.execute_reply":"2022-11-12T12:28:43.651977Z"},"trusted":true},"execution_count":169,"outputs":[{"name":"stdout","text":"tensor([  101,  3189,  2053,  2047, 24265,  2097,  2272,  2013,  2569,  9517,\n         2728, 26774,  2015, 15113,  2053,  2047, 24265,  2097,  2272,  2013,\n         2569,  9517,  2728, 26774,  2015,  3607, 15113,  2044,  2002,  7864,\n         2010,  2345,  3189,  2000,  4905,  2236,  2520, 19820,  3674, 13307,\n         2024,  7316,  1037,  3026,  3425,  2533,  2880,  2409,  1996,  2899,\n         2695,  2008, 26774,  5292,  2025,  6749,  2151,  2582, 24265,  1996,\n         4812,  2003,  3143,  3425,  2533,  3764, 26760, 20778, 14884,  2072,\n        13970,  5051,  2278,  2409,  1996,  3780,  1996, 26774, 15113,  2387,\n         2195,  2306,  8398,  8753, 21801,  2021,  2025,  8398,  2155,  2030,\n         8398,  2370,  2070,  3862,  3275,  2040,  2031, 12254,  5905,  1999,\n         3715, 29217,  2013, 26774,  2015,  4812,  2024,  8398,  2280,  3167,\n         4905,  2745,  9946,  8398,  2280,  3049,  3472,  2703, 24951, 13028,\n         1998,  2280,  2317,  2160,  2120,  3036, 11747,  2745, 13259,   102,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_predictions","metadata":{"id":"kvL9QevsHsFf","execution":{"iopub.status.busy":"2022-11-12T12:28:43.654708Z","iopub.execute_input":"2022-11-12T12:28:43.655272Z","iopub.status.idle":"2022-11-12T12:28:43.703053Z","shell.execute_reply.started":"2022-11-12T12:28:43.655238Z","shell.execute_reply":"2022-11-12T12:28:43.701950Z"},"trusted":true},"execution_count":170,"outputs":[{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"[array([[-1.4365268 ,  1.4984101 ,  0.07322286],\n        [-0.5493527 ,  0.19064377,  0.21301213]], dtype=float32),\n array([[-0.29887602,  0.04576249,  0.00530763],\n        [-1.3622594 ,  1.485631  ,  0.03222483]], dtype=float32),\n array([[-2.525451  ,  1.6536273 ,  0.88541156],\n        [-1.2913784 ,  0.6269392 ,  0.54168355]], dtype=float32),\n array([[-1.388296  ,  1.4923276 ,  0.04677911],\n        [ 5.618216  , -2.1153097 , -3.588841  ]], dtype=float32),\n array([[-0.962977  ,  0.79522026,  0.07264277],\n        [ 5.6306834 , -2.1049752 , -3.6007624 ]], dtype=float32),\n array([[ 5.6189237 , -2.1062634 , -3.5711184 ],\n        [ 1.9873694 , -0.11316261, -2.1579328 ]], dtype=float32),\n array([[-1.5207295 ,  1.7511055 , -0.25510335],\n        [ 5.626681  , -2.0573573 , -3.646981  ]], dtype=float32),\n array([[ 5.6059203 , -2.0663013 , -3.6086245 ],\n        [-1.7707437 ,  1.679633  ,  0.01031851]], dtype=float32),\n array([[ 5.6087523, -2.1024652, -3.563128 ],\n        [ 5.602485 , -2.1068351, -3.531203 ]], dtype=float32),\n array([[ 5.615246 , -2.110949 , -3.5355835],\n        [-1.6556993,  1.7958808, -0.2640687]], dtype=float32),\n array([[ 5.593299 , -2.0248456, -3.6715696],\n        [ 5.224602 , -1.6849339, -3.7148194]], dtype=float32),\n array([[ 5.6214614, -2.1073575, -3.6018422],\n        [ 5.6260624, -2.1130507, -3.587249 ]], dtype=float32),\n array([[ 5.6315274, -2.1054451, -3.6138492],\n        [ 5.606954 , -2.0943005, -3.6293404]], dtype=float32),\n array([[ 5.6056457 , -2.0349996 , -3.6556304 ],\n        [-1.583624  ,  1.6186632 , -0.20997337]], dtype=float32),\n array([[ 5.6043086 , -2.0950344 , -3.6454215 ],\n        [-0.40112755, -0.00949283,  0.01477918]], dtype=float32),\n array([[-1.6770818 ,  1.6780409 , -0.06445301],\n        [ 5.3854    , -1.7771848 , -3.780047  ]], dtype=float32),\n array([[ 5.6242385, -2.06675  , -3.6383276],\n        [ 5.600469 , -2.0784152, -3.6428378]], dtype=float32),\n array([[ 1.5702902 ,  0.12319408, -1.846482  ],\n        [ 5.6066875 , -2.1220176 , -3.5934627 ]], dtype=float32),\n array([[ 5.6175737, -2.1214237, -3.578449 ],\n        [ 5.6103654, -2.101062 , -3.6179433]], dtype=float32),\n array([[ 5.6024814, -2.0939894, -3.643912 ],\n        [ 5.6282597, -2.1030364, -3.592044 ]], dtype=float32),\n array([[-1.7685969 ,  1.7496439 , -0.16546358],\n        [ 5.6174283 , -2.0455196 , -3.6307988 ]], dtype=float32),\n array([[ 5.6161523, -2.1041205, -3.5970416],\n        [ 5.632879 , -2.1039646, -3.5778494]], dtype=float32),\n array([[ 5.6206284, -2.0949178, -3.5800676],\n        [ 5.5113664, -1.87109  , -3.76936  ]], dtype=float32),\n array([[ 5.6223893, -2.1159086, -3.5761507],\n        [ 5.627521 , -2.0647526, -3.6114764]], dtype=float32),\n array([[ 5.6179676, -2.0553107, -3.6764593],\n        [ 5.633512 , -2.1058543, -3.608977 ]], dtype=float32),\n array([[ 5.62177  , -2.089005 , -3.5824764],\n        [ 5.627265 , -2.107734 , -3.5787325]], dtype=float32),\n array([[ 5.600734 , -2.045872 , -3.620479 ],\n        [ 5.6274734, -2.10401  , -3.6107392]], dtype=float32),\n array([[ 5.5125813, -1.9055076, -3.7930632],\n        [ 5.627792 , -2.0713108, -3.6337564]], dtype=float32),\n array([[ 5.5813417, -2.0859416, -3.6434612],\n        [ 5.6185284, -2.080943 , -3.5870013]], dtype=float32),\n array([[ 5.5977325, -2.0034773, -3.6731634],\n        [ 5.623608 , -2.1224196, -3.5484836]], dtype=float32),\n array([[ 5.6045384, -2.106165 , -3.6275315],\n        [ 5.6347494, -2.095224 , -3.6300678]], dtype=float32),\n array([[ 5.6260457, -2.1086037, -3.5693505],\n        [ 5.5783715, -1.9444299, -3.7257373]], dtype=float32),\n array([[ 5.61527  , -2.0628018, -3.616626 ],\n        [ 5.6272497, -2.1071596, -3.6047864]], dtype=float32),\n array([[ 5.6197786, -2.1233885, -3.5659199],\n        [ 5.5644875, -1.9496834, -3.748785 ]], dtype=float32),\n array([[ 5.6210155, -2.0907953, -3.5759134],\n        [ 5.6352057, -2.083749 , -3.637349 ]], dtype=float32),\n array([[ 5.6184015, -2.0987349, -3.5614822],\n        [ 5.6329255, -2.105069 , -3.6073873]], dtype=float32),\n array([[ 5.6132975, -2.0682123, -3.6232438],\n        [ 5.5958486, -2.0166352, -3.657214 ]], dtype=float32),\n array([[ 5.6173854, -2.0813763, -3.5768301],\n        [ 5.623794 , -2.1116133, -3.6094987]], dtype=float32),\n array([[ 5.6244845, -2.1121435, -3.5991335],\n        [ 5.6155314, -2.1128442, -3.6074607]], dtype=float32),\n array([[ 5.6231117, -2.1098082, -3.6083696],\n        [ 5.6109385, -2.109098 , -3.6179368]], dtype=float32),\n array([[ 5.614009 , -2.0108151, -3.6524692],\n        [ 5.6134176, -2.095272 , -3.5796328]], dtype=float32),\n array([[ 5.628385 , -2.1090631, -3.6022546],\n        [ 5.3327823, -1.6894513, -3.7204795]], dtype=float32),\n array([[ 5.316583 , -1.7673336, -3.7958977],\n        [ 5.5839562, -2.0176272, -3.7132554]], dtype=float32),\n array([[ 5.5631123, -1.9727912, -3.756906 ],\n        [ 5.6198525, -2.1208022, -3.5731592]], dtype=float32),\n array([[ 5.5545664, -1.9473608, -3.7333872],\n        [ 5.619792 , -2.1172364, -3.5764704]], dtype=float32),\n array([[ 5.621953 , -2.0817308, -3.5811942],\n        [ 5.622399 , -2.096544 , -3.5779893]], dtype=float32),\n array([[ 5.6292896, -2.0887802, -3.5844243],\n        [ 5.62361  , -2.1070166, -3.6200137]], dtype=float32),\n array([[ 5.5724144, -1.9970815, -3.6269107],\n        [ 5.598733 , -2.0208843, -3.614888 ]], dtype=float32),\n array([[ 5.6180124, -2.1067362, -3.5785513],\n        [ 5.6024837, -2.0548928, -3.5573816]], dtype=float32),\n array([[ 5.6095266, -2.0526156, -3.6429346],\n        [ 5.623563 , -2.1078072, -3.5585494]], dtype=float32),\n array([[ 5.0243416, -1.5990181, -3.6810093],\n        [ 5.60821  , -2.1145568, -3.5396686]], dtype=float32),\n array([[ 5.617814 , -2.1222322, -3.5707169],\n        [ 5.61213  , -2.1074831, -3.6217113]], dtype=float32),\n array([[ 5.62343  , -2.1132069, -3.5874205],\n        [ 5.6251435, -2.0984898, -3.6197298]], dtype=float32),\n array([[ 5.6252704, -2.0919974, -3.6175184],\n        [ 5.3191824, -1.806831 , -3.759648 ]], dtype=float32),\n array([[ 5.6297116, -2.0892558, -3.602439 ],\n        [ 5.6313076, -2.1052358, -3.5983922]], dtype=float32),\n array([[ 5.588502 , -2.0788057, -3.5275426],\n        [ 5.6219225, -2.1180882, -3.5915961]], dtype=float32),\n array([[ 5.5591016, -1.9805231, -3.639545 ],\n        [ 5.5812516, -1.9935384, -3.7399411]], dtype=float32),\n array([[ 5.6101823, -2.0720034, -3.56952  ],\n        [ 5.619453 , -2.1218257, -3.6037447]], dtype=float32),\n array([[ 5.4147906, -1.908581 , -3.7612371],\n        [ 5.6145124, -2.0437143, -3.6429126]], dtype=float32),\n array([[ 5.620241 , -2.093287 , -3.5896313],\n        [ 5.625627 , -2.1096036, -3.6133413]], dtype=float32),\n array([[ 5.6256547, -2.063963 , -3.637932 ],\n        [ 5.5678988, -1.9474375, -3.7418807]], dtype=float32),\n array([[-1.6422346 ,  1.4698567 , -0.07804697],\n        [-1.7015318 ,  1.7707962 , -0.21690865]], dtype=float32),\n array([[ 5.553958 , -1.9073427, -3.6776738],\n        [ 5.620209 , -2.0998228, -3.5931895]], dtype=float32),\n array([[ 5.0215583, -1.5541142, -3.6633022],\n        [ 5.629188 , -2.1090736, -3.5998578]], dtype=float32),\n array([[ 5.623484 , -2.1183376, -3.569215 ],\n        [ 5.4479256, -1.8896142, -3.7558103]], dtype=float32),\n array([[ 5.6090612, -2.035141 , -3.6586459],\n        [ 5.5984855, -2.0396793, -3.5722046]], dtype=float32),\n array([[ 5.626598 , -2.1103618, -3.6112223],\n        [ 5.611886 , -2.0736134, -3.5890665]], dtype=float32),\n array([[ 3.877659  , -0.9490239 , -3.1404235 ],\n        [-1.0272099 ,  0.81959224,  0.0719683 ]], dtype=float32),\n array([[ 5.6039233, -2.0690491, -3.571765 ],\n        [ 5.6226435, -2.052979 , -3.6782794]], dtype=float32),\n array([[ 5.6328893, -2.09503  , -3.615539 ],\n        [ 5.5846844, -2.0087826, -3.6975574]], dtype=float32),\n array([[ 5.628965 , -2.1037033, -3.5835035],\n        [ 5.5925756, -2.0702348, -3.5913002]], dtype=float32),\n array([[-1.0238136 ,  0.85215   ,  0.05571922],\n        [ 5.6145883 , -2.106892  , -3.549059  ]], dtype=float32),\n array([[ 5.6250095, -2.1138775, -3.6162527],\n        [ 5.618267 , -2.1034784, -3.6006966]], dtype=float32),\n array([[ 5.6040554, -2.050639 , -3.6539304],\n        [ 5.6181617, -2.1081288, -3.5786178]], dtype=float32),\n array([[ 5.6314945, -2.0995197, -3.6142583],\n        [ 5.6201982, -2.0970984, -3.573381 ]], dtype=float32),\n array([[ 5.6281934, -2.1076274, -3.6196098],\n        [ 5.6279836, -2.0517926, -3.6636267]], dtype=float32),\n array([[ 5.6260314, -2.0313215, -3.6323087],\n        [ 5.6216383, -2.113114 , -3.5781348]], dtype=float32),\n array([[ 5.627385 , -2.0295322, -3.6506574],\n        [ 5.6134906, -2.1019063, -3.568558 ]], dtype=float32),\n array([[ 5.619755 , -2.096763 , -3.6348875],\n        [-1.7300539,  1.7429111, -0.0770218]], dtype=float32),\n array([[-0.9651647,  1.3901242, -0.5027083],\n        [ 3.1760592, -0.8488795, -2.8072412]], dtype=float32),\n array([[ 5.6247206, -2.084712 , -3.5999188],\n        [ 5.601458 , -2.1042328, -3.6136513]], dtype=float32),\n array([[ 5.613895 , -2.1152081, -3.5780036],\n        [ 5.5851016, -2.0068905, -3.717082 ]], dtype=float32),\n array([[ 5.624911 , -2.0929852, -3.634826 ],\n        [ 5.4606333, -1.8187484, -3.7850864]], dtype=float32),\n array([[ 5.606294  , -2.0641239 , -3.5964339 ],\n        [-1.6378123 ,  1.5669055 , -0.10411936]], dtype=float32),\n array([[ 5.629152 , -2.0741045, -3.6595118],\n        [ 5.5901284, -2.001853 , -3.7289534]], dtype=float32),\n array([[ 5.6181483, -2.0363796, -3.6189902],\n        [ 5.2796235, -1.6433117, -3.6543636]], dtype=float32),\n array([[ 5.6319404, -2.0830572, -3.6142807],\n        [ 5.6109548, -2.1142979, -3.602175 ]], dtype=float32),\n array([[ 5.6145015, -2.1166155, -3.6002183],\n        [ 5.6160455, -2.1130593, -3.5716536]], dtype=float32),\n array([[ 5.6049914, -2.0810223, -3.547338 ],\n        [ 5.618506 , -2.1099396, -3.5756445]], dtype=float32),\n array([[ 5.616072 , -2.0863442, -3.596044 ],\n        [ 5.625685 , -2.1157691, -3.5840733]], dtype=float32),\n array([[ 5.6099687, -2.1240847, -3.5877466],\n        [ 5.598583 , -2.061125 , -3.567996 ]], dtype=float32),\n array([[ 5.622526 , -2.1070814, -3.608346 ],\n        [ 5.595198 , -2.1045442, -3.6125548]], dtype=float32),\n array([[ 5.4127135, -1.7219476, -3.7168493],\n        [ 5.627791 , -2.1069417, -3.6230092]], dtype=float32),\n array([[ 5.6055355, -2.056369 , -3.6945877],\n        [-1.1570417,  1.4891149, -0.5212798]], dtype=float32),\n array([[ 5.522982 , -1.8654714, -3.7954612],\n        [ 5.629697 , -2.106439 , -3.6125977]], dtype=float32),\n array([[ 4.9852147, -1.5852171, -3.7088883],\n        [ 5.6233397, -2.0906518, -3.6009855]], dtype=float32),\n array([[ 5.6305423, -2.089945 , -3.6182117],\n        [ 5.623512 , -2.1139646, -3.588037 ]], dtype=float32),\n array([[ 5.633371 , -2.0752296, -3.6207168],\n        [ 5.620742 , -2.1104255, -3.5847185]], dtype=float32),\n array([[ 5.592679 , -1.9996052, -3.7110507],\n        [ 5.621906 , -2.100493 , -3.6227446]], dtype=float32),\n array([[ 5.6034646, -2.0559933, -3.666159 ],\n        [ 5.612794 , -2.0914059, -3.5968132]], dtype=float32),\n array([[-1.5913373,  1.7569456, -0.2645402],\n        [ 5.6255894, -2.0775928, -3.635676 ]], dtype=float32),\n array([[ 5.6165037, -2.1008048, -3.627744 ],\n        [ 4.836908 , -1.5173595, -3.640653 ]], dtype=float32),\n array([[ 5.62968  , -2.0818362, -3.616385 ],\n        [ 5.6181297, -2.1085339, -3.6027844]], dtype=float32),\n array([[ 5.6127825, -2.1166165, -3.6105838],\n        [ 5.6179132, -2.1015809, -3.572913 ]], dtype=float32),\n array([[ 5.584662 , -1.9539306, -3.696212 ],\n        [-1.5817095,  1.6727208, -0.269239 ]], dtype=float32),\n array([[-0.8425776 ,  1.0928404 , -0.35072362],\n        [ 5.591233  , -1.9596012 , -3.7203274 ]], dtype=float32),\n array([[ 5.6305585, -2.1014802, -3.631221 ],\n        [ 5.4310145, -1.7800448, -3.7738242]], dtype=float32),\n array([[ 5.6259437, -2.1062927, -3.5953326],\n        [ 5.6234565, -2.1110973, -3.598975 ]], dtype=float32),\n array([[ 5.6236453, -2.0862315, -3.600088 ],\n        [ 5.553271 , -1.9530413, -3.7188852]], dtype=float32),\n array([[ 5.5906186, -2.0194497, -3.6788344],\n        [ 5.620664 , -2.1203575, -3.5983558]], dtype=float32),\n array([[ 5.6137276, -2.1281164, -3.5528035],\n        [ 5.627459 , -2.1017208, -3.5905776]], dtype=float32),\n array([[ 5.6235037, -2.045403 , -3.617282 ],\n        [ 5.622258 , -2.1062615, -3.6206162]], dtype=float32),\n array([[ 5.5872083, -2.0700984, -3.607648 ],\n        [ 5.6229887, -2.0920823, -3.5726826]], dtype=float32),\n array([[ 5.6185875, -2.1284332, -3.5684626],\n        [ 5.6252933, -2.1013782, -3.6333246]], dtype=float32),\n array([[ 5.565813 , -1.9308289, -3.7506416],\n        [ 5.316632 , -1.7198231, -3.7318563]], dtype=float32),\n array([[-1.3374852,  1.7347964, -0.5606667],\n        [ 5.6140475, -2.0188634, -3.7052712]], dtype=float32),\n array([[ 5.58962  , -2.0095718, -3.6457088],\n        [ 4.9424005, -1.673906 , -3.238917 ]], dtype=float32),\n array([[ 5.607139 , -2.084647 , -3.5797017],\n        [ 5.574014 , -1.9543927, -3.6626685]], dtype=float32),\n array([[ 5.5599995, -2.0627823, -3.6137884],\n        [ 5.616385 , -2.0845418, -3.6281295]], dtype=float32),\n array([[ 5.6024704, -2.0149484, -3.7005553],\n        [ 5.626228 , -2.109928 , -3.5943332]], dtype=float32),\n array([[ 5.6201935, -2.1230803, -3.5832498],\n        [ 5.6143384, -2.0991383, -3.5559046]], dtype=float32),\n array([[-0.3613524 , -0.02963097,  0.02759923],\n        [ 5.466142  , -1.8091115 , -3.7979512 ]], dtype=float32),\n array([[ 5.626939 , -2.1055899, -3.6055288],\n        [ 5.594929 , -2.101881 , -3.633633 ]], dtype=float32),\n array([[ 5.6162477, -1.9851415, -3.69212  ],\n        [ 4.5158095, -1.2990628, -3.496871 ]], dtype=float32),\n array([[ 5.6222625, -2.1180167, -3.5888216],\n        [ 4.0913353, -1.044235 , -3.2331014]], dtype=float32),\n array([[ 5.617357 , -2.0914886, -3.6503596],\n        [ 5.614587 , -2.1065621, -3.5959477]], dtype=float32),\n array([[ 5.512342 , -1.9644852, -3.7439718],\n        [ 5.616189 , -2.1001275, -3.6331625]], dtype=float32),\n array([[ 5.6079903, -2.0696657, -3.5828006],\n        [ 5.6338544, -2.088259 , -3.6059623]], dtype=float32),\n array([[ 5.63026  , -2.0793314, -3.6608956],\n        [ 5.5979576, -2.0414913, -3.6398103]], dtype=float32),\n array([[ 5.6190877, -2.1078918, -3.6280854],\n        [ 5.6259885, -2.1072745, -3.5777025]], dtype=float32),\n array([[ 5.4870825, -1.8246982, -3.6257448],\n        [ 5.629493 , -2.0987644, -3.6153655]], dtype=float32),\n array([[ 5.5549397, -1.9205714, -3.783877 ],\n        [ 5.582808 , -1.984057 , -3.7205026]], dtype=float32),\n array([[ 5.614735 , -2.1212597, -3.5898533],\n        [ 5.618993 , -2.1098037, -3.585062 ]], dtype=float32),\n array([[ 5.6203017, -2.0644011, -3.6401722],\n        [ 5.611827 , -2.1234732, -3.565264 ]], dtype=float32),\n array([[ 5.617583 , -2.0773563, -3.6307802],\n        [ 5.629864 , -2.1053538, -3.5905268]], dtype=float32),\n array([[ 5.139414 , -1.6480469, -3.7014155],\n        [ 5.6265917, -2.102804 , -3.6067235]], dtype=float32),\n array([[ 5.617892 , -2.106654 , -3.591548 ],\n        [ 5.628569 , -2.0808885, -3.5769086]], dtype=float32),\n array([[ 5.6141367, -2.080886 , -3.6107566],\n        [ 5.6047463, -2.064285 , -3.6076102]], dtype=float32),\n array([[ 5.321408 , -1.8299327, -3.7736487],\n        [ 5.6144958, -2.0352898, -3.6677291]], dtype=float32),\n array([[ 5.6176915, -2.092226 , -3.5917618],\n        [ 5.609561 , -2.0888722, -3.616671 ]], dtype=float32),\n array([[ 5.6326213, -2.0985942, -3.5881734],\n        [ 5.6171703, -2.0766191, -3.6557066]], dtype=float32),\n array([[ 5.6113105, -2.1174684, -3.600624 ],\n        [ 5.6278   , -2.0978827, -3.593485 ]], dtype=float32),\n array([[ 5.6138735, -2.1138117, -3.5888302],\n        [ 5.6203756, -2.1102386, -3.542931 ]], dtype=float32),\n array([[ 5.632935 , -2.0841572, -3.6257846],\n        [ 5.5967307, -2.0888033, -3.578937 ]], dtype=float32),\n array([[ 5.632788 , -2.084612 , -3.6114805],\n        [ 5.614859 , -2.1030786, -3.5655184]], dtype=float32),\n array([[ 5.615804 , -2.1055033, -3.6150868],\n        [ 5.6197853, -2.0246084, -3.6201444]], dtype=float32),\n array([[ 5.6259937, -2.1154897, -3.5817587],\n        [ 5.6274853, -2.0814722, -3.5992632]], dtype=float32),\n array([[ 0.6711791 ,  0.30190206, -1.287254  ],\n        [ 5.62274   , -2.0801325 , -3.6078424 ]], dtype=float32),\n array([[ 4.1383324, -1.2394413, -3.3568523],\n        [ 5.6104693, -2.104641 , -3.6302607]], dtype=float32),\n array([[ 5.6348977, -2.0983422, -3.626539 ],\n        [ 5.6303077, -2.089064 , -3.622582 ]], dtype=float32),\n array([[ 5.6225705, -2.117719 , -3.585116 ],\n        [ 5.607142 , -2.0939448, -3.5660398]], dtype=float32),\n array([[ 5.6284003, -2.105319 , -3.6123962],\n        [ 5.6344347, -2.0894387, -3.6258829]], dtype=float32),\n array([[-0.65989673,  1.2990364 , -0.9356742 ],\n        [ 5.6108418 , -2.1253612 , -3.5530894 ]], dtype=float32),\n array([[ 5.6330943, -2.0950816, -3.6373594],\n        [ 5.618003 , -2.1179438, -3.5902438]], dtype=float32),\n array([[ 5.608051 , -2.0834744, -3.54498  ],\n        [ 5.451466 , -1.8476237, -3.7856107]], dtype=float32),\n array([[ 5.586865 , -2.0216885, -3.630223 ],\n        [ 5.598039 , -2.0794363, -3.6508567]], dtype=float32),\n array([[ 5.633524 , -2.0544739, -3.6454625],\n        [ 5.6272707, -2.0957959, -3.5883625]], dtype=float32),\n array([[ 5.45066  , -1.8345115, -3.7593365],\n        [ 5.6215873, -2.1181123, -3.5806818]], dtype=float32),\n array([[ 5.5642734, -1.9652512, -3.7070806],\n        [ 5.576456 , -2.083914 , -3.488619 ]], dtype=float32),\n array([[ 5.62053  , -2.1004825, -3.6064878],\n        [ 5.570522 , -1.9532338, -3.7380905]], dtype=float32),\n array([[ 5.6251225, -2.0262885, -3.6206694],\n        [ 5.297912 , -1.5713065, -3.725101 ]], dtype=float32),\n array([[ 5.6156416, -2.0970924, -3.6317625],\n        [ 5.626538 , -2.0741847, -3.6226835]], dtype=float32),\n array([[ 5.601067 , -2.0528789, -3.6086197],\n        [ 5.0216637, -1.5890012, -3.6952317]], dtype=float32),\n array([[ 5.6068544, -2.0427787, -3.665778 ],\n        [ 5.628823 , -2.102714 , -3.59558  ]], dtype=float32),\n array([[ 5.6241837, -2.1165967, -3.5696106],\n        [ 4.936632 , -1.609313 , -3.6610804]], dtype=float32),\n array([[ 5.58633  , -2.0109472, -3.6518617],\n        [ 5.6188073, -2.0592453, -3.653513 ]], dtype=float32),\n array([[ 5.612807 , -2.0802612, -3.563263 ],\n        [ 5.627071 , -2.0967045, -3.5697365]], dtype=float32),\n array([[-1.6255596 ,  1.733409  , -0.20829035],\n        [ 5.60809   , -2.1024628 , -3.6165888 ]], dtype=float32),\n array([[ 5.5829263, -1.9944482, -3.6942437],\n        [ 5.619637 , -2.110161 , -3.596287 ]], dtype=float32),\n array([[ 5.606256 , -2.1186352, -3.5383272],\n        [ 5.6144633, -2.1206992, -3.553139 ]], dtype=float32),\n array([[ 5.1014957, -1.4600263, -3.7169912],\n        [ 5.5784645, -1.9840117, -3.7082605]], dtype=float32),\n array([[ 5.619942 , -2.0989838, -3.6354556],\n        [ 5.6187425, -2.0907261, -3.6197746]], dtype=float32),\n array([[ 5.616022 , -2.1044123, -3.5477858],\n        [ 5.635597 , -2.0908084, -3.589751 ]], dtype=float32),\n array([[ 5.614079 , -2.111572 , -3.5699837],\n        [ 5.6119013, -2.1064353, -3.5565279]], dtype=float32),\n array([[ 5.4724846, -1.9201887, -3.7424788],\n        [ 5.6191998, -2.0925338, -3.6226714]], dtype=float32),\n array([[ 5.6133237 , -2.0798738 , -3.5884705 ],\n        [-1.7303714 ,  1.7898486 , -0.05812711]], dtype=float32),\n array([[ 5.538612 , -1.8885885, -3.7249322],\n        [ 5.6103683, -2.1101148, -3.6119153]], dtype=float32),\n array([[ 5.5430307, -1.8781793, -3.7512689],\n        [ 5.6230216, -2.0985131, -3.6382627]], dtype=float32),\n array([[ 5.6217065, -2.1155536, -3.5641963],\n        [ 5.365567 , -1.83092  , -3.7749257]], dtype=float32),\n array([[ 5.395124  , -1.7860277 , -3.735712  ],\n        [-1.6858141 ,  1.6192328 , -0.09529381]], dtype=float32),\n array([[ 4.2559943, -1.033001 , -3.346218 ],\n        [ 5.621722 , -2.1162517, -3.5916047]], dtype=float32),\n array([[ 5.624001 , -2.1045988, -3.580296 ],\n        [ 5.3656993, -1.7436774, -3.7697635]], dtype=float32),\n array([[ 5.6224346, -2.081881 , -3.6372786],\n        [ 5.5906515, -2.0851815, -3.6514635]], dtype=float32),\n array([[ 5.626935 , -2.0862243, -3.6094236],\n        [ 5.614726 , -2.0434177, -3.607336 ]], dtype=float32),\n array([[ 5.6249576, -2.073178 , -3.6501036],\n        [ 5.6249137, -2.1060631, -3.5806484]], dtype=float32),\n array([[ 5.619388 , -2.0778022, -3.5671353],\n        [ 5.6223593, -2.094984 , -3.5614512]], dtype=float32),\n array([[ 5.5873027, -1.9639771, -3.7191527],\n        [ 5.5919056, -2.0504794, -3.6100855]], dtype=float32),\n array([[ 5.6277432, -2.0309672, -3.655139 ],\n        [ 4.6152987, -1.1933789, -3.5319986]], dtype=float32),\n array([[ 5.5277243, -1.9201337, -3.7548048],\n        [ 5.6386886, -2.104222 , -3.5912156]], dtype=float32),\n array([[ 5.5886536, -1.9957122, -3.6625202],\n        [ 5.498011 , -1.8334453, -3.702412 ]], dtype=float32),\n array([[ 5.622619 , -2.0631776, -3.6312752],\n        [ 5.615419 , -2.0274363, -3.660021 ]], dtype=float32),\n array([[-1.3746156 ,  1.1986786 , -0.05941018],\n        [ 5.632792  , -2.0701883 , -3.648882  ]], dtype=float32),\n array([[-0.61337197,  0.35012573,  0.04713397],\n        [ 5.5800586 , -2.054538  , -3.5321794 ]], dtype=float32),\n array([[ 5.619581 , -2.0986376, -3.5703366],\n        [ 5.5683455, -1.9532138, -3.7253602]], dtype=float32),\n array([[ 5.626359 , -2.098076 , -3.5905972],\n        [ 5.5462866, -1.9656103, -3.738353 ]], dtype=float32),\n array([[ 5.6287847 , -2.0875745 , -3.6361613 ],\n        [-1.6211541 ,  1.7310797 , -0.19077143]], dtype=float32),\n array([[ 5.6231503, -2.119613 , -3.5687644],\n        [ 5.5292463, -1.9479883, -3.7428231]], dtype=float32),\n array([[ 5.6063647, -2.114156 , -3.594296 ],\n        [ 5.625672 , -2.10475  , -3.6242163]], dtype=float32),\n array([[ 5.612436 , -2.1076827, -3.629551 ],\n        [ 5.460379 , -1.8859313, -3.760115 ]], dtype=float32),\n array([[-1.6471217 ,  1.6672742 , -0.09582412],\n        [-1.6627519 ,  1.8261094 , -0.20214887]], dtype=float32),\n array([[ 5.617784 , -2.1275992, -3.5659542],\n        [ 5.617314 , -2.1107717, -3.5665045]], dtype=float32),\n array([[ 4.0425563, -1.1722167, -3.184955 ],\n        [ 5.5975223, -2.103501 , -3.628091 ]], dtype=float32),\n array([[ 5.0052953, -1.4351543, -3.6838126],\n        [ 5.0052953, -1.4351543, -3.6838126]], dtype=float32),\n array([[ 5.601567 , -2.0620017, -3.5809016],\n        [ 5.542247 , -1.9386629, -3.7202916]], dtype=float32),\n array([[ 5.6111507, -2.0971465, -3.559982 ],\n        [ 5.613133 , -2.104579 , -3.631077 ]], dtype=float32),\n array([[ 4.6188684, -1.4632361, -3.5365071],\n        [ 5.613077 , -2.083463 , -3.57101  ]], dtype=float32),\n array([[ 5.564846 , -1.9470043, -3.6790204],\n        [ 3.209226 , -0.8389992, -2.6670787]], dtype=float32),\n array([[ 5.6165414 , -2.095246  , -3.5817213 ],\n        [ 0.29470783,  0.35301328, -0.8126109 ]], dtype=float32),\n array([[ 5.619115 , -2.1232142, -3.58639  ],\n        [ 5.615392 , -2.0805945, -3.5869567]], dtype=float32),\n array([[ 5.411245 , -1.8692878, -3.7968109],\n        [ 5.616922 , -2.0647376, -3.6136332]], dtype=float32),\n array([[ 5.6284904, -2.1023757, -3.621622 ],\n        [ 5.4434123, -1.783789 , -3.7641592]], dtype=float32),\n array([[-1.573768  ,  1.4311603 , -0.08618665],\n        [-1.3336957 ,  1.4774686 ,  0.01501373]], dtype=float32),\n array([[-1.4038866 ,  1.4953312 ,  0.05290093],\n        [-1.3373975 ,  1.4786326 ,  0.01751584]], dtype=float32),\n array([[-1.3372353 ,  1.4785192 ,  0.0171083 ],\n        [-0.45891243,  0.10165606,  0.06624604]], dtype=float32),\n array([[-1.5342139 ,  1.4533184 ,  0.13287501],\n        [-0.7707967 ,  0.3866507 ,  0.127551  ]], dtype=float32),\n array([[-1.3340552 ,  1.4776351 ,  0.01539902],\n        [-1.3532226 ,  1.4830112 ,  0.02659581]], dtype=float32),\n array([[-1.3237625 ,  1.4745994 ,  0.00973354]], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"flat_train_predictions = [item for sublist in train_predictions for item in sublist]\nflat_train_predictions = np.argmax(flat_train_predictions, axis=1).flatten()\n\nflat_train_predictions","metadata":{"id":"vSHnJvUSH10b","execution":{"iopub.status.busy":"2022-11-12T12:28:43.704557Z","iopub.execute_input":"2022-11-12T12:28:43.705019Z","iopub.status.idle":"2022-11-12T12:28:43.716357Z","shell.execute_reply.started":"2022-11-12T12:28:43.704981Z","shell.execute_reply":"2022-11-12T12:28:43.715204Z"},"trusted":true},"execution_count":171,"outputs":[{"execution_count":171,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"markdown","source":"#  The Final Predictions on the Validation Set","metadata":{}},{"cell_type":"code","source":"## Convert flat_predictions to \"str\"\n\nflat_predictions=label_encoder.inverse_transform(flat_predictions)\nflat_predictions","metadata":{"id":"XJL-1sEOqCMd","execution":{"iopub.status.busy":"2022-11-12T12:28:43.718370Z","iopub.execute_input":"2022-11-12T12:28:43.718797Z","iopub.status.idle":"2022-11-12T12:28:43.726710Z","shell.execute_reply.started":"2022-11-12T12:28:43.718759Z","shell.execute_reply":"2022-11-12T12:28:43.725550Z"},"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"array(['reporting', 'reporting', 'satire', 'reporting', 'reporting',\n       'reporting', 'satire', 'satire', 'reporting', 'reporting',\n       'satire', 'reporting', 'opinion', 'satire', 'reporting',\n       'reporting', 'reporting', 'reporting', 'reporting', 'reporting',\n       'reporting', 'reporting', 'reporting', 'reporting', 'satire',\n       'reporting', 'reporting', 'satire', 'reporting', 'reporting',\n       'reporting', 'reporting', 'opinion', 'opinion', 'reporting',\n       'reporting', 'reporting', 'satire', 'reporting', 'reporting',\n       'satire', 'reporting', 'reporting', 'reporting', 'reporting',\n       'reporting', 'reporting', 'reporting', 'reporting', 'satire',\n       'reporting', 'reporting', 'reporting', 'reporting', 'reporting',\n       'reporting', 'reporting', 'reporting', 'reporting', 'reporting',\n       'satire', 'reporting', 'reporting', 'reporting', 'opinion',\n       'satire', 'reporting', 'reporting', 'satire', 'reporting',\n       'reporting', 'satire', 'reporting', 'reporting', 'reporting',\n       'reporting', 'reporting', 'reporting', 'satire', 'opinion',\n       'reporting', 'satire', 'reporting'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"out_fn=\"output-subtask1-dev_bert-en5.txt\"\n\nout = pd.DataFrame(flat_predictions, test.index)\nout.to_csv(out_fn, sep='\\t', header=None)\nprint('Results on: ', out_fn)\n","metadata":{"id":"aUR-xWWGNwcz","execution":{"iopub.status.busy":"2022-11-12T12:28:43.728413Z","iopub.execute_input":"2022-11-12T12:28:43.729100Z","iopub.status.idle":"2022-11-12T12:28:43.737285Z","shell.execute_reply.started":"2022-11-12T12:28:43.729066Z","shell.execute_reply":"2022-11-12T12:28:43.736165Z"},"trusted":true},"execution_count":173,"outputs":[{"name":"stdout","text":"Results on:  output-subtask1-dev_bert-en5.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the Model using torch.save()","metadata":{}},{"cell_type":"code","source":"state = {\n    'epoch': epochs,\n    'state_dict': model.state_dict(),\n    'optimizer': optimizer.state_dict(),\n    \n}\n","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:28:43.739841Z","iopub.execute_input":"2022-11-12T12:28:43.740611Z","iopub.status.idle":"2022-11-12T12:28:43.749521Z","shell.execute_reply.started":"2022-11-12T12:28:43.740560Z","shell.execute_reply":"2022-11-12T12:28:43.748353Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"import shutil\ndef save_ckp(state,checkpoint_path):\n    \"\"\"\n    state: checkpoint we want to save\n    checkpoint_path: path to save checkpoint\n    \n    \"\"\"\n    f_path = checkpoint_path\n\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:38:54.358015Z","iopub.execute_input":"2022-11-12T12:38:54.358373Z","iopub.status.idle":"2022-11-12T12:38:54.363726Z","shell.execute_reply.started":"2022-11-12T12:38:54.358344Z","shell.execute_reply":"2022-11-12T12:38:54.362737Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"save_ckp(state,\"finalcheckpoint_semeval_best.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-11-12T12:39:03.301964Z","iopub.execute_input":"2022-11-12T12:39:03.302327Z","iopub.status.idle":"2022-11-12T12:39:05.847484Z","shell.execute_reply.started":"2022-11-12T12:39:03.302297Z","shell.execute_reply":"2022-11-12T12:39:05.845989Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions","metadata":{}},{"cell_type":"markdown","source":"The Bert-Model is able to perform appreciably on the Validation Set with a macro-f1 score of 0.4127 and a micro-f1 score of 0.60241 which is ranked 2nd in the leaderboards at the present moment. One of the things to note is that the class label \"satire\" is quite underrepresented in the training dataset as a result of which it may be difficult to learn. To counter this an area to look at are loss functions that are able to capture the unbalanced nature of the dataset. We could also look at ensemble models to make our predictions. We should also make an effort to look at the self attention weights between the words to understand and explain the relationships captured between them.","metadata":{}}]}